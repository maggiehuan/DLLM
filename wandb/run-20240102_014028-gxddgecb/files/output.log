Encoder CNN shapes: {'image': (64, 64, 3)}
Encoder MLP shapes: {'transition_tokens': (384,)}
Decoder CNN shapes: {'image': (64, 64, 3)}
Decoder MLP shapes: {'transition_tokens': (384,)}
JAX devices (1): [cuda(id=0)]
Policy devices: cuda:0
Train devices:  cuda:0
Tracing train function.
no rnd data in data
Optimizer model_opt has 197,057,283 variables.
Optimizer actor_opt has 9,464,849 variables.
Optimizer critic_opt has 9,708,799 variables.
Logdir /home/ziyu/logdir/ziyu_crafter_cuda_0_seed_0
Observation space:
  image            Space(dtype=uint8, shape=(64, 64, 3), low=0, high=255)
  transition_tokens Space(dtype=uint32, shape=(384,), low=0, high=4294967295)
  goal_tokens      Space(dtype=uint32, shape=(5, 384), low=0, high=4294967295)
  goal_id          Space(dtype=uint32, shape=(5,), low=0, high=4294967295)
  reward           Space(dtype=float32, shape=(), low=-inf, high=inf)
  is_first         Space(dtype=bool, shape=(), low=False, high=True)
  is_last          Space(dtype=bool, shape=(), low=False, high=True)
  is_terminal      Space(dtype=bool, shape=(), low=False, high=True)
  log_reward       Space(dtype=float32, shape=(1,), low=-inf, high=inf)
  log_achievement_collect_coal Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_collect_diamond Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_collect_drink Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_collect_iron Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_collect_sapling Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_collect_stone Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_collect_wood Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_defeat_skeleton Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_defeat_zombie Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_eat_cow Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_eat_plant Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_make_iron_pickaxe Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_make_iron_sword Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_make_stone_pickaxe Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_make_stone_sword Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_make_wood_pickaxe Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_make_wood_sword Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_place_furnace Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_place_plant Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_place_stone Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_place_table Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
  log_achievement_wake_up Space(dtype=int32, shape=(), low=-2147483648, high=2147483647)
Action space:
  action           Space(dtype=float32, shape=(17,), low=0, high=1)
  reset            Space(dtype=bool, shape=(), low=False, high=True)
Prefill train dataset.
Episode has 157 steps and return 2.1.
Episode has 157 steps and return 2.1.
Episode has 139 steps and return 0.1.
Episode has 75 steps and return -0.9.
Episode has 218 steps and return 2.1.
Episode has 212 steps and return 1.1.
Saved chunk: 20240102T014057F514097-4wcwCmjrBAR4Vsk6m64r57-5kZHLKCeLUewB8qQcWrLF5-1024.npz
Prefill eval dataset.
Episode has 178 steps and return 0.1.
Episode has 146 steps and return 0.1.
Episode has 209 steps and return 2.1.
Episode has 139 steps and return 1.1.
Episode has 145 steps and return 2.1.
Episode has 151 steps and return 2.1.
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /home/ziyu/logdir/ziyu_crafter_cuda_0_seed_0
Saved chunk: 20240102T014110F562306-6DiIrGM1dSUnjISwrAG4Ow-5LjyZVTTm8nIvxVpKFaaYe-1024.npz
[92mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [39m[1mStep 1100[92m[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
episode/length [1m212[22m [34m/[39m episode/score [1m1.1[22m [34m/[39m episode/reward_rate [1m1[22m [34m/[39m eval_episode/length [1m151[22m [34m/[39m eval_episode/score [1m2.1[22m [34m/[39m eval_episode/reward_rate [1m0.99[22m [34m/[39m train_stats/sum_log_reward [1m1.1
[34m/[39m train_stats/max_log_achievement_collect_sapling [1m1.5[22m [34m/[39m train_stats/max_log_achievement_place_plant [1m1[22m [34m/[39m train_stats/max_log_achievement_wake_up [1m1.83[22m [34m/
train_stats/max_log_achievement_collect_wood [1m1[22m [34m/[39m eval_stats/sum_log_reward [1m1.27[22m [34m/[39m eval_stats/max_log_achievement_collect_sapling [1m1.17[22m [34m/
eval_stats/max_log_achievement_collect_wood [1m0[22m [34m/[39m eval_stats/max_log_achievement_place_plant [1m0.67[22m [34m/[39m eval_stats/max_log_achievement_wake_up [1m2
Creating new TensorBoard event file writer.
Did not find any checkpoint.
Writing checkpoint: /home/ziyu/logdir/ziyu_crafter_cuda_0_seed_0/checkpoint.ckpt
Start training loop.
Starting evaluation at step 1100
Saved chunk: 20240102T014122F279102-5LjyZVTTm8nIvxVpKFaaYe-0000000000000000000000-76.npz
Saved chunk: 20240102T014108F865890-5kZHLKCeLUewB8qQcWrLF5-0000000000000000000000-76.npz
Tracing policy function.
Wrote checkpoint: /home/ziyu/logdir/ziyu_crafter_cuda_0_seed_0/checkpoint.ckpt
Tracing policy function.
Episode has 189 steps and return 1.1.
Tracing policy function.
Tracing train function.
Tracing report function.
Tracing report function.
Tracing report function.
[92mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [39m[1mStep 1101[92m[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
eval_episode/length [1m189[22m [34m/[39m eval_episode/score [1m1.1[22m [34m/[39m eval_episode/reward_rate [1m0.99[22m [34m/[39m eval_stats/sum_log_reward [1m1.1[22m [34m/[39m eval_stats/max_log_achievement_collect_sapling [1m1[22m [34m/
eval_stats/max_log_achievement_collect_wood [1m0[22m [34m/[39m eval_stats/max_log_achievement_place_plant [1m1[22m [34m/[39m eval_stats/max_log_achievement_wake_up [1m3[22m [34m/[39m train/action_mag [1m16[22m [34m/[39m train/action_max
[1m16[22m [34m/[39m train/action_mean [1m8.03[22m [34m/[39m train/action_min [1m0[22m [34m/[39m train/action_std [1m4.36[22m [34m/[39m train/actor_opt_actor_opt_grad_overflow [1m0[22m [34m/[39m train/actor_opt_actor_opt_grad_scale [1m1e4[22m [34m/
train/actor_opt_grad_norm [1m3.1e-4[22m [34m/[39m train/actor_opt_grad_steps [1m1[22m [34m/[39m train/actor_opt_loss [1m-1.32[22m [34m/[39m train/adv_mag [1m0[22m [34m/[39m train/adv_max [1m0[22m [34m/[39m train/adv_mean [1m0[22m [34m/[39m train/adv_min [1m0[22m [34m/
train/adv_std [1m0[22m [34m/[39m train/cont_avg [1m1[22m [34m/[39m train/cont_loss_mean [1m0.8[22m [34m/[39m train/cont_loss_std [1m0.3[22m [34m/[39m train/cont_neg_acc [1m0.5[22m [34m/[39m train/cont_neg_loss [1m0.72[22m [34m/[39m train/cont_pos_acc [1m0.41[22m [34m/
train/cont_pos_loss [1m0.8[22m [34m/[39m train/cont_pred [1m0.47[22m [34m/[39m train/cont_rate [1m1[22m [34m/[39m train/dyn_loss_mean [1m10.57[22m [34m/[39m train/dyn_loss_std [1m0.54[22m [34m/[39m train/extr_critic_critic_opt_critic_opt_grad_overflow [1m0
[34m/[39m train/extr_critic_critic_opt_critic_opt_grad_scale [1m1e4[22m [34m/[39m train/extr_critic_critic_opt_grad_norm [1m4.83[22m [34m/[39m train/extr_critic_critic_opt_grad_steps [1m1[22m [34m/
train/extr_critic_critic_opt_loss [1m1.9e4[22m [34m/[39m train/extr_critic_mag [1m0[22m [34m/[39m train/extr_critic_max [1m0[22m [34m/[39m train/extr_critic_mean [1m0[22m [34m/[39m train/extr_critic_min [1m0[22m [34m/[39m train/extr_critic_std [1m0[22m [34m/
train/extr_return_normed_mag [1m0[22m [34m/[39m train/extr_return_normed_max [1m0[22m [34m/[39m train/extr_return_normed_mean [1m0[22m [34m/[39m train/extr_return_normed_min [1m0[22m [34m/[39m train/extr_return_normed_std [1m0[22m [34m/
train/extr_return_rate [1m0[22m [34m/[39m train/extr_return_raw_mag [1m0[22m [34m/[39m train/extr_return_raw_max [1m0[22m [34m/[39m train/extr_return_raw_mean [1m0[22m [34m/[39m train/extr_return_raw_min [1m0[22m [34m/[39m train/extr_return_raw_std [1m0[22m [34m/
train/extr_reward_mag [1m0[22m [34m/[39m train/extr_reward_max [1m0[22m [34m/[39m train/extr_reward_mean [1m0[22m [34m/[39m train/extr_reward_min [1m0[22m [34m/[39m train/extr_reward_std [1m0[22m [34m/[39m train/image_loss_mean [1m3916.94[22m [34m/
train/image_loss_std [1m239.79[22m [34m/[39m train/model_loss_mean [1m4140.79[22m [34m/[39m train/model_loss_std [1m237.61[22m [34m/[39m train/model_opt_grad_norm nan [34m/[39m train/model_opt_grad_steps [1m0[22m [34m/[39m train/model_opt_loss
[1m4.1e7[22m [34m/[39m train/model_opt_model_opt_grad_overflow [1m1[22m [34m/[39m train/model_opt_model_opt_grad_scale [1m5000[22m [34m/[39m train/policy_entropy_mag [1m2.79[22m [34m/[39m train/policy_entropy_max [1m2.79[22m [34m/
train/policy_entropy_mean [1m2.58[22m [34m/[39m train/policy_entropy_min [1m1.67[22m [34m/[39m train/policy_entropy_std [1m0.1[22m [34m/[39m train/policy_logprob_mag [1m5.22[22m [34m/[39m train/policy_logprob_max [1m-0.47[22m [34m/
train/policy_logprob_mean [1m-2.59[22m [34m/[39m train/policy_logprob_min [1m-5.22[22m [34m/[39m train/policy_logprob_std [1m0.7[22m [34m/[39m train/policy_randomness_mag [1m0.98[22m [34m/[39m train/policy_randomness_max [1m0.98[22m [34m/
train/policy_randomness_mean [1m0.91[22m [34m/[39m train/policy_randomness_min [1m0.59[22m [34m/[39m train/policy_randomness_std [1m0.04[22m [34m/[39m train/post_ent_mag [1m106.2[22m [34m/[39m train/post_ent_max [1m106.2[22m [34m/
train/post_ent_mean [1m105.61[22m [34m/[39m train/post_ent_min [1m104.96[22m [34m/[39m train/post_ent_std [1m0.21[22m [34m/[39m train/prior_ent_mag [1m106.66[22m [34m/[39m train/prior_ent_max [1m106.66[22m [34m/[39m train/prior_ent_mean [1m105.66[22m [34m/
train/prior_ent_min [1m104.57[22m [34m/[39m train/prior_ent_std [1m0.34[22m [34m/[39m train/rep_loss_mean [1m10.57[22m [34m/[39m train/rep_loss_std [1m0.54[22m [34m/[39m train/reward_avg [1m0.01[22m [34m/[39m train/reward_loss_mean [1m5.54[22m [34m/
train/reward_loss_std [1m9.5e-7[22m [34m/[39m train/reward_max_data [1m1[22m [34m/[39m train/reward_max_pred [1m0[22m [34m/[39m train/reward_neg_acc [1m1[22m [34m/[39m train/reward_neg_loss [1m5.54[22m [34m/[39m train/reward_pos_acc [1m0[22m [34m/
train/reward_pos_loss [1m5.54[22m [34m/[39m train/reward_pred [1m0[22m [34m/[39m train/reward_rate [1m0.01[22m [34m/[39m train/transition_tokens_loss_mean [1m211.16[22m [34m/[39m train/transition_tokens_loss_std [1m14.85[22m [34m/
train/params_agent/wm/model_opt [1m2e8[22m [34m/[39m train/params_agent/task_behavior/critic/critic_opt [1m9.7e6[22m [34m/[39m train/params_agent/task_behavior/ac/actor_opt [1m9.5e6[22m [34m/[39m report/cont_avg [1m1[22m [34m/
report/cont_loss_mean [1m0.77[22m [34m/[39m report/cont_loss_std [1m0.29[22m [34m/[39m report/cont_neg_acc [1m0.25[22m [34m/[39m report/cont_neg_loss [1m0.79[22m [34m/[39m report/cont_pos_acc [1m0.44[22m [34m/[39m report/cont_pos_loss [1m0.77[22m [34m/
report/cont_pred [1m0.48[22m [34m/[39m report/cont_rate [1m1[22m [34m/[39m report/dyn_loss_mean [1m10.48[22m [34m/[39m report/dyn_loss_std [1m0.5[22m [34m/[39m report/image_loss_mean [1m3913.41[22m [34m/[39m report/image_loss_std [1m243.99[22m [34m/
report/model_loss_mean [1m4137.48[22m [34m/[39m report/model_loss_std [1m244.22[22m [34m/[39m report/post_ent_mag [1m106.28[22m [34m/[39m report/post_ent_max [1m106.28[22m [34m/[39m report/post_ent_mean [1m105.62[22m [34m/[39m report/post_ent_min [1m105.09
[34m/[39m report/post_ent_std [1m0.2[22m [34m/[39m report/prior_ent_mag [1m106.86[22m [34m/[39m report/prior_ent_max [1m106.86[22m [34m/[39m report/prior_ent_mean [1m105.68[22m [34m/[39m report/prior_ent_min [1m104.76[22m [34m/[39m report/prior_ent_std [1m0.34[22m [34m/
report/rep_loss_mean [1m10.48[22m [34m/[39m report/rep_loss_std [1m0.5[22m [34m/[39m report/reward_avg [1m0.01[22m [34m/[39m report/reward_loss_mean [1m5.54[22m [34m/[39m report/reward_loss_std [1m9.5e-7[22m [34m/[39m report/reward_max_data [1m1[22m [34m/
report/reward_max_pred [1m0[22m [34m/[39m report/reward_neg_acc [1m1[22m [34m/[39m report/reward_neg_loss [1m5.54[22m [34m/[39m report/reward_pos_acc [1m0[22m [34m/[39m report/reward_pos_loss [1m5.54[22m [34m/[39m report/reward_pred [1m0[22m [34m/
report/reward_rate [1m0.01[22m [34m/[39m report/transition_tokens_loss_mean [1m211.47[22m [34m/[39m report/transition_tokens_loss_std [1m15.38[22m [34m/[39m eval/cont_avg [1m0.99[22m [34m/[39m eval/cont_loss_mean [1m0.79[22m [34m/[39m eval/cont_loss_std
[1m0.32[22m [34m/[39m eval/cont_neg_acc [1m0.25[22m [34m/[39m eval/cont_neg_loss [1m0.88[22m [34m/[39m eval/cont_pos_acc [1m0.43[22m [34m/[39m eval/cont_pos_loss [1m0.79[22m [34m/[39m eval/cont_pred [1m0.48[22m [34m/[39m eval/cont_rate [1m0.99[22m [34m/[39m eval/dyn_loss_mean [1m10.43
[34m/[39m eval/dyn_loss_std [1m0.54[22m [34m/[39m eval/image_loss_mean [1m3951.37[22m [34m/[39m eval/image_loss_std [1m187.62[22m [34m/[39m eval/model_loss_mean [1m4172.01[22m [34m/[39m eval/model_loss_std [1m186.46[22m [34m/[39m eval/post_ent_mag [1m106.21[22m [34m/
eval/post_ent_max [1m106.21[22m [34m/[39m eval/post_ent_mean [1m105.67[22m [34m/[39m eval/post_ent_min [1m105.14[22m [34m/[39m eval/post_ent_std [1m0.2[22m [34m/[39m eval/prior_ent_mag [1m106.69[22m [34m/[39m eval/prior_ent_max [1m106.69[22m [34m/
eval/prior_ent_mean [1m105.67[22m [34m/[39m eval/prior_ent_min [1m104.56[22m [34m/[39m eval/prior_ent_std [1m0.34[22m [34m/[39m eval/rep_loss_mean [1m10.43[22m [34m/[39m eval/rep_loss_std [1m0.54[22m [34m/[39m eval/reward_avg [1m9.7e-3[22m [34m/
eval/reward_loss_mean [1m5.54[22m [34m/[39m eval/reward_loss_std [1m9.6e-7[22m [34m/[39m eval/reward_max_data [1m1[22m [34m/[39m eval/reward_max_pred [1m0[22m [34m/[39m eval/reward_neg_acc [1m1[22m [34m/[39m eval/reward_neg_loss [1m5.54[22m [34m/
eval/reward_pos_acc [1m0[22m [34m/[39m eval/reward_pos_loss [1m5.54[22m [34m/[39m eval/reward_pred [1m0[22m [34m/[39m eval/reward_rate [1m0.02[22m [34m/[39m eval/transition_tokens_loss_mean [1m208.04[22m [34m/[39m eval/transition_tokens_loss_std [1m14[22m [34m/
replay/size [1m1038[22m [34m/[39m replay/inserts [1m1038[22m [34m/[39m replay/samples [1m112[22m [34m/[39m replay/insert_wait_avg [1m2.3e-6[22m [34m/[39m replay/insert_wait_frac [1m1[22m [34m/[39m replay/sample_wait_avg [1m1.4e-6[22m [34m/[39m replay/sample_wait_frac
[1m1[22m [34m/[39m eval_replay/size [1m1227[22m [34m/[39m eval_replay/inserts [1m1227[22m [34m/[39m eval_replay/samples [1m112[22m [34m/[39m eval_replay/insert_wait_avg [1m2.4e-6[22m [34m/[39m eval_replay/insert_wait_frac [1m1[22m [34m/[39m eval_replay/sample_wait_avg
[1m1.5e-6[22m [34m/[39m eval_replay/sample_wait_frac [1m1[22m [34m/[39m timer/duration [1m163.15[22m [34m/[39m timer/env.step_count [1m1101[22m [34m/[39m timer/env.step_total [1m12.57[22m [34m/[39m timer/env.step_frac [1m0.08[22m [34m/[39m timer/env.step_avg [1m0.01[22m [34m/
timer/env.step_min [1m2.6e-3[22m [34m/[39m timer/env.step_max [1m1.5[22m [34m/[39m timer/replay._sample_count [1m112[22m [34m/[39m timer/replay._sample_total [1m30.73[22m [34m/[39m timer/replay._sample_frac [1m0.19[22m [34m/[39m timer/replay._sample_avg
[1m0.27[22m [34m/[39m timer/replay._sample_min [1m0.06[22m [34m/[39m timer/replay._sample_max [1m2.47[22m [34m/[39m timer/agent.save_count [1m1[22m [34m/[39m timer/agent.save_total [1m1.23[22m [34m/[39m timer/agent.save_frac [1m7.6e-3[22m [34m/
timer/agent.save_avg [1m1.23[22m [34m/[39m timer/agent.save_min [1m1.23[22m [34m/[39m timer/agent.save_max [1m1.23[22m [34m/[39m timer/agent.policy_count [1m191[22m [34m/[39m timer/agent.policy_total [1m9.53[22m [34m/[39m timer/agent.policy_frac [1m0.06[22m [34m/
timer/agent.policy_avg [1m0.05[22m [34m/[39m timer/agent.policy_min [1m8.3e-3[22m [34m/[39m timer/agent.policy_max [1m5.91[22m [34m/[39m timer/dataset_train_count [1m1[22m [34m/[39m timer/dataset_train_total [1m7.2e-5[22m [34m/
timer/dataset_train_frac [1m4.4e-7[22m [34m/[39m timer/dataset_train_avg [1m7.2e-5[22m [34m/[39m timer/dataset_train_min [1m7.2e-5[22m [34m/[39m timer/dataset_train_max [1m7.2e-5[22m [34m/[39m timer/agent.train_count [1m1[22m [34m/
timer/agent.train_total [1m97.83[22m [34m/[39m timer/agent.train_frac [1m0.6[22m [34m/[39m timer/agent.train_avg [1m97.83[22m [34m/[39m timer/agent.train_min [1m97.83[22m [34m/[39m timer/agent.train_max [1m97.83[22m [34m/[39m timer/agent.report_count [1m2
[34m/[39m timer/agent.report_total [1m21.83[22m [34m/[39m timer/agent.report_frac [1m0.13[22m [34m/[39m timer/agent.report_avg [1m10.91[22m [34m/[39m timer/agent.report_min [1m5.75[22m [34m/[39m timer/agent.report_max [1m16.07[22m [34m/
timer/dataset_eval_count [1m1[22m [34m/[39m timer/dataset_eval_total [1m9.4e-5[22m [34m/[39m timer/dataset_eval_frac [1m5.8e-7[22m [34m/[39m timer/dataset_eval_avg [1m9.4e-5[22m [34m/[39m timer/dataset_eval_min [1m9.4e-5[22m [34m/
timer/dataset_eval_max [1m9.4e-5
Episode has 162 steps and return 3.1.
Episode has 196 steps and return 3.1.
Episode has 155 steps and return 2.1.
Episode has 144 steps and return 0.1.
Episode has 193 steps and return 0.1.
Episode has 35 steps and return -0.9.
Saved chunk: 20240102T014108F865890-5kZHLKCeLUewB8qQcWrLF5-3BsTQhu75TkwGUg2sZM20H-1024.npz
Episode has 199 steps and return 1.1.
Episode has 167 steps and return 0.1.
[92mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [39m[1mStep 2293[92m[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
episode/length [1m167[22m [34m/[39m episode/score [1m0.1[22m [34m/[39m episode/reward_rate [1m0.97[22m [34m/[39m train/action_mag [1m16[22m [34m/[39m train/action_max [1m16[22m [34m/[39m train/action_mean [1m6.07[22m [34m/[39m train/action_min [1m0[22m [34m/[39m train/action_std
[1m3.96[22m [34m/[39m train/actor_opt_actor_opt_grad_overflow [1m0[22m [34m/[39m train/actor_opt_actor_opt_grad_scale [1m1e4[22m [34m/[39m train/actor_opt_grad_norm [1m0.02[22m [34m/[39m train/actor_opt_grad_steps [1m300[22m [34m/
train/actor_opt_loss [1m390.02[22m [34m/[39m train/adv_mag [1m1.64[22m [34m/[39m train/adv_max [1m1.64[22m [34m/[39m train/adv_mean [1m0.05[22m [34m/[39m train/adv_min [1m-0.39[22m [34m/[39m train/adv_std [1m0.17[22m [34m/[39m train/cont_avg [1m0.99[22m [34m/
train/cont_loss_mean [1m0.04[22m [34m/[39m train/cont_loss_std [1m0.27[22m [34m/[39m train/cont_neg_acc [1m0.09[22m [34m/[39m train/cont_neg_loss [1m3.33[22m [34m/[39m train/cont_pos_acc [1m0.99[22m [34m/[39m train/cont_pos_loss [1m0.02[22m [34m/[39m train/cont_pred
[1m0.98[22m [34m/[39m train/cont_rate [1m0.99[22m [34m/[39m train/dyn_loss_mean [1m5.3[22m [34m/[39m train/dyn_loss_std [1m9.14[22m [34m/[39m train/extr_critic_critic_opt_critic_opt_grad_overflow [1m0[22m [34m/
train/extr_critic_critic_opt_critic_opt_grad_scale [1m1e4[22m [34m/[39m train/extr_critic_critic_opt_grad_norm [1m10.65[22m [34m/[39m train/extr_critic_critic_opt_grad_steps [1m300[22m [34m/
train/extr_critic_critic_opt_loss [1m2.9e4[22m [34m/[39m train/extr_critic_mag [1m0.06[22m [34m/[39m train/extr_critic_max [1m0.06[22m [34m/[39m train/extr_critic_mean [1m0.06[22m [34m/[39m train/extr_critic_min [1m0.06[22m [34m/
train/extr_critic_std [1m7.1e-4[22m [34m/[39m train/extr_return_normed_mag [1m1.71[22m [34m/[39m train/extr_return_normed_max [1m1.71[22m [34m/[39m train/extr_return_normed_mean [1m0.12[22m [34m/[39m train/extr_return_normed_min [1m-0.32[22m [34m/
train/extr_return_normed_std [1m0.17[22m [34m/[39m train/extr_return_rate [1m0.03[22m [34m/[39m train/extr_return_raw_mag [1m1.71[22m [34m/[39m train/extr_return_raw_max [1m1.71[22m [34m/[39m train/extr_return_raw_mean [1m0.11[22m [34m/
train/extr_return_raw_min [1m-0.34[22m [34m/[39m train/extr_return_raw_std [1m0.17[22m [34m/[39m train/extr_reward_mag [1m0.38[22m [34m/[39m train/extr_reward_max [1m0.38[22m [34m/[39m train/extr_reward_mean [1m8.6e-3[22m [34m/[39m train/extr_reward_min
[1m-0.1[22m [34m/[39m train/extr_reward_std [1m0.03[22m [34m/[39m train/image_loss_mean [1m151.54[22m [34m/[39m train/image_loss_std [1m53.92[22m [34m/[39m train/model_loss_mean [1m158.94[22m [34m/[39m train/model_loss_std [1m55.49[22m [34m/
train/model_opt_grad_norm [1m353.63[22m [34m/[39m train/model_opt_grad_steps [1m290[22m [34m/[39m train/model_opt_loss [1m2248.44[22m [34m/[39m train/model_opt_model_opt_grad_overflow [1m0.02[22m [34m/
train/model_opt_model_opt_grad_scale [1m9.77[22m [34m/[39m train/policy_entropy_mag [1m2.09[22m [34m/[39m train/policy_entropy_max [1m2.09[22m [34m/[39m train/policy_entropy_mean [1m1.57[22m [34m/[39m train/policy_entropy_min [1m1.31[22m [34m/
train/policy_entropy_std [1m0.14[22m [34m/[39m train/policy_logprob_mag [1m6.14[22m [34m/[39m train/policy_logprob_max [1m-0.64[22m [34m/[39m train/policy_logprob_mean [1m-1.57[22m [34m/[39m train/policy_logprob_min [1m-6.14[22m [34m/
train/policy_logprob_std [1m0.81[22m [34m/[39m train/policy_randomness_mag [1m0.74[22m [34m/[39m train/policy_randomness_max [1m0.74[22m [34m/[39m train/policy_randomness_mean [1m0.55[22m [34m/[39m train/policy_randomness_min [1m0.46[22m [34m/
train/policy_randomness_std [1m0.05[22m [34m/[39m train/post_ent_mag [1m60.8[22m [34m/[39m train/post_ent_max [1m60.8[22m [34m/[39m train/post_ent_mean [1m36.9[22m [34m/[39m train/post_ent_min [1m20.4[22m [34m/[39m train/post_ent_std [1m9.69[22m [34m/
train/prior_ent_mag [1m63.95[22m [34m/[39m train/prior_ent_max [1m63.95[22m [34m/[39m train/prior_ent_mean [1m43.19[22m [34m/[39m train/prior_ent_min [1m24.98[22m [34m/[39m train/prior_ent_std [1m8.36[22m [34m/[39m train/rep_loss_mean [1m5.3[22m [34m/
train/rep_loss_std [1m9.14[22m [34m/[39m train/reward_avg [1m8.8e-3[22m [34m/[39m train/reward_loss_mean [1m0.52[22m [34m/[39m train/reward_loss_std [1m0.67[22m [34m/[39m train/reward_max_data [1m1[22m [34m/[39m train/reward_max_pred [1m0.43[22m [34m/
train/reward_neg_acc [1m1[22m [34m/[39m train/reward_neg_loss [1m0.48[22m [34m/[39m train/reward_pos_acc [1m0.36[22m [34m/[39m train/reward_pos_loss [1m3.5[22m [34m/[39m train/reward_pred [1m5.1e-3[22m [34m/[39m train/reward_rate [1m0.01[22m [34m/
train/transition_tokens_loss_mean [1m3.66[22m [34m/[39m train/transition_tokens_loss_std [1m0.3[22m [34m/[39m train_stats/sum_log_reward [1m1.1[22m [34m/[39m train_stats/max_log_achievement_collect_sapling [1m2.5[22m [34m/
train_stats/max_log_achievement_collect_wood [1m0.62[22m [34m/[39m train_stats/max_log_achievement_place_plant [1m0.38[22m [34m/[39m train_stats/max_log_achievement_wake_up [1m1.25[22m [34m/[39m train_stats/mean_log_entropy
[1m1.68[22m [34m/[39m train_stats/max_log_achievement_collect_drink [1m0.5[22m [34m/[39m report/cont_avg [1m1[22m [34m/[39m report/cont_loss_mean [1m5.9e-3[22m [34m/[39m report/cont_loss_std [1m0.09[22m [34m/[39m report/cont_neg_acc [1m0.33[22m [34m/
report/cont_neg_loss [1m1.46[22m [34m/[39m report/cont_pos_acc [1m1[22m [34m/[39m report/cont_pos_loss [1m1.6e-3[22m [34m/[39m report/cont_pred [1m1[22m [34m/[39m report/cont_rate [1m1[22m [34m/[39m report/dyn_loss_mean [1m4.42[22m [34m/[39m report/dyn_loss_std [1m6.36[22m [34m/
report/image_loss_mean [1m30.28[22m [34m/[39m report/image_loss_std [1m19.18[22m [34m/[39m report/model_loss_mean [1m33.06[22m [34m/[39m report/model_loss_std [1m21.46[22m [34m/[39m report/post_ent_mag [1m44.45[22m [34m/[39m report/post_ent_max [1m44.45[22m [34m/
report/post_ent_mean [1m25.91[22m [34m/[39m report/post_ent_min [1m13.48[22m [34m/[39m report/post_ent_std [1m5.77[22m [34m/[39m report/prior_ent_mag [1m56.57[22m [34m/[39m report/prior_ent_max [1m56.57[22m [34m/[39m report/prior_ent_mean [1m31.91[22m [34m/
report/prior_ent_min [1m11.53[22m [34m/[39m report/prior_ent_std [1m8.58[22m [34m/[39m report/rep_loss_mean [1m4.42[22m [34m/[39m report/rep_loss_std [1m6.36[22m [34m/[39m report/reward_avg [1m0.02[22m [34m/[39m report/reward_loss_mean [1m0.1[22m [34m/
report/reward_loss_std [1m0.42[22m [34m/[39m report/reward_max_data [1m1[22m [34m/[39m report/reward_max_pred [1m0.97[22m [34m/[39m report/reward_neg_acc [1m0.98[22m [34m/[39m report/reward_neg_loss [1m0.07[22m [34m/[39m report/reward_pos_acc [1m0.95[22m [34m/
report/reward_pos_loss [1m1.4[22m [34m/[39m report/reward_pred [1m0.02[22m [34m/[39m report/reward_rate [1m0.02[22m [34m/[39m report/transition_tokens_loss_mean [1m0.02[22m [34m/[39m report/transition_tokens_loss_std [1m8.6e-3[22m [34m/
eval/cont_avg [1m1[22m [34m/[39m eval/cont_loss_mean [1m0.03[22m [34m/[39m eval/cont_loss_std [1m0.47[22m [34m/[39m eval/cont_neg_acc [1m0[22m [34m/[39m eval/cont_neg_loss [1m7.44[22m [34m/[39m eval/cont_pos_acc [1m1[22m [34m/[39m eval/cont_pos_loss [1m1.4e-4[22m [34m/
eval/cont_pred [1m1[22m [34m/[39m eval/cont_rate [1m1[22m [34m/[39m eval/dyn_loss_mean [1m7.2[22m [34m/[39m eval/dyn_loss_std [1m9.82[22m [34m/[39m eval/image_loss_mean [1m56.74[22m [34m/[39m eval/image_loss_std [1m59.78[22m [34m/[39m eval/model_loss_mean [1m61.21[22m [34m/
eval/model_loss_std [1m61.88[22m [34m/[39m eval/post_ent_mag [1m56.22[22m [34m/[39m eval/post_ent_max [1m56.22[22m [34m/[39m eval/post_ent_mean [1m26.64[22m [34m/[39m eval/post_ent_min [1m13.73[22m [34m/[39m eval/post_ent_std [1m7.94[22m [34m/[39m eval/prior_ent_mag
[1m64.6[22m [34m/[39m eval/prior_ent_max [1m64.6[22m [34m/[39m eval/prior_ent_mean [1m30.96[22m [34m/[39m eval/prior_ent_min [1m11.31[22m [34m/[39m eval/prior_ent_std [1m9.67[22m [34m/[39m eval/rep_loss_mean [1m7.2[22m [34m/[39m eval/rep_loss_std [1m9.82[22m [34m/
eval/reward_avg [1m9e-3[22m [34m/[39m eval/reward_loss_mean [1m0.1[22m [34m/[39m eval/reward_loss_std [1m0.72[22m [34m/[39m eval/reward_max_data [1m1[22m [34m/[39m eval/reward_max_pred [1m0.97[22m [34m/[39m eval/reward_neg_acc [1m1[22m [34m/[39m eval/reward_neg_loss
[1m0.06[22m [34m/[39m eval/reward_pos_acc [1m0.54[22m [34m/[39m eval/reward_pos_loss [1m3.44[22m [34m/[39m eval/reward_pred [1m7.6e-3[22m [34m/[39m eval/reward_rate [1m0.01[22m [34m/[39m eval/transition_tokens_loss_mean [1m0.02[22m [34m/
eval/transition_tokens_loss_std [1m8.1e-3[22m [34m/[39m replay/size [1m2230[22m [34m/[39m replay/inserts [1m1192[22m [34m/[39m replay/samples [1m9536[22m [34m/[39m replay/insert_wait_avg [1m3.9e-6[22m [34m/[39m replay/insert_wait_frac [1m1[22m [34m/
replay/sample_wait_avg [1m1.3e-6[22m [34m/[39m replay/sample_wait_frac [1m1[22m [34m/[39m eval_replay/size [1m1227[22m [34m/[39m eval_replay/inserts [1m0[22m [34m/[39m eval_replay/samples [1m16[22m [34m/[39m eval_replay/insert_wait_avg nan [34m/
eval_replay/insert_wait_frac nan [34m/[39m eval_replay/sample_wait_avg [1m1.6e-6[22m [34m/[39m eval_replay/sample_wait_frac [1m1[22m [34m/[39m timer/duration [1m279[22m [34m/[39m timer/env.step_count [1m1192[22m [34m/[39m timer/env.step_total
[1m14.74[22m [34m/[39m timer/env.step_frac [1m0.05[22m [34m/[39m timer/env.step_avg [1m0.01[22m [34m/[39m timer/env.step_min [1m2.5e-3[22m [34m/[39m timer/env.step_max [1m1.34[22m [34m/[39m timer/replay._sample_count [1m9536[22m [34m/[39m timer/replay._sample_total
[1m528.51[22m [34m/[39m timer/replay._sample_frac [1m1.89[22m [34m/[39m timer/replay._sample_avg [1m0.06[22m [34m/[39m timer/replay._sample_min [1m7.8e-3[22m [34m/[39m timer/replay._sample_max [1m0.12[22m [34m/[39m timer/agent.save_count [1m0[22m [34m/
timer/agent.save_total [1m0[22m [34m/[39m timer/agent.save_frac [1m0[22m [34m/[39m timer/agent.policy_count [1m1192[22m [34m/[39m timer/agent.policy_total [1m11.95[22m [34m/[39m timer/agent.policy_frac [1m0.04[22m [34m/[39m timer/agent.policy_avg [1m0.01[22m [34m/
timer/agent.policy_min [1m8.6e-3[22m [34m/[39m timer/agent.policy_max [1m0.02[22m [34m/[39m timer/dataset_train_count [1m596[22m [34m/[39m timer/dataset_train_total [1m0.08[22m [34m/[39m timer/dataset_train_frac [1m3e-4[22m [34m/
timer/dataset_train_avg [1m1.4e-4[22m [34m/[39m timer/dataset_train_min [1m1.1e-4[22m [34m/[39m timer/dataset_train_max [1m1.1e-3[22m [34m/[39m timer/agent.train_count [1m596[22m [34m/[39m timer/agent.train_total [1m234.83[22m [34m/
timer/agent.train_frac [1m0.84[22m [34m/[39m timer/agent.train_avg [1m0.39[22m [34m/[39m timer/agent.train_min [1m0.38[22m [34m/[39m timer/agent.train_max [1m0.41[22m [34m/[39m timer/agent.report_count [1m2[22m [34m/[39m timer/agent.report_total [1m0.45[22m [34m/
timer/agent.report_frac [1m1.6e-3[22m [34m/[39m timer/agent.report_avg [1m0.23[22m [34m/[39m timer/agent.report_min [1m0.23[22m [34m/[39m timer/agent.report_max [1m0.23[22m [34m/[39m timer/dataset_eval_count [1m1[22m [34m/[39m timer/dataset_eval_total
[1m5.1e-5[22m [34m/[39m timer/dataset_eval_frac [1m1.8e-7[22m [34m/[39m timer/dataset_eval_avg [1m5.1e-5[22m [34m/[39m timer/dataset_eval_min [1m5.1e-5[22m [34m/[39m timer/dataset_eval_max [1m5.1e-5[22m [34m/[39m fps [1m4.27
Episode has 338 steps and return 0.1.
Episode has 180 steps and return 1.1.
Episode has 218 steps and return 0.1.
Saved chunk: 20240102T014717F077290-3BsTQhu75TkwGUg2sZM20H-3Z1hYgFS9wWbFolf4ikosX-1024.npz
Episode has 204 steps and return 1.1.
Episode has 194 steps and return 0.1.
Episode has 188 steps and return 0.1.
[92mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [39m[1mStep 3593[92m[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
episode/length [1m188[22m [34m/[39m episode/score [1m0.1[22m [34m/[39m episode/reward_rate [1m0.98[22m [34m/[39m train/action_mag [1m16[22m [34m/[39m train/action_max [1m16[22m [34m/[39m train/action_mean [1m5.03[22m [34m/[39m train/action_min [1m0[22m [34m/[39m train/action_std
[1m0.58[22m [34m/[39m train/actor_opt_actor_opt_grad_overflow [1m0[22m [34m/[39m train/actor_opt_actor_opt_grad_scale [1m1e4[22m [34m/[39m train/actor_opt_grad_norm [1m3.3e-4[22m [34m/[39m train/actor_opt_grad_steps [1m920[22m [34m/
train/actor_opt_loss [1m40.97[22m [34m/[39m train/adv_mag [1m4.16[22m [34m/[39m train/adv_max [1m4.16[22m [34m/[39m train/adv_mean [1m0.06[22m [34m/[39m train/adv_min [1m-0.96[22m [34m/[39m train/adv_std [1m0.37[22m [34m/[39m train/cont_avg [1m0.99[22m [34m/[39m train/cont_loss_mean
[1m1e-2[22m [34m/[39m train/cont_loss_std [1m0.14[22m [34m/[39m train/cont_neg_acc [1m0.57[22m [34m/[39m train/cont_neg_loss [1m1.2[22m [34m/[39m train/cont_pos_acc [1m1[22m [34m/[39m train/cont_pos_loss [1m3e-3[22m [34m/[39m train/cont_pred [1m0.99[22m [34m/[39m train/cont_rate
[1m0.99[22m [34m/[39m train/dyn_loss_mean [1m4.01[22m [34m/[39m train/dyn_loss_std [1m5.64[22m [34m/[39m train/extr_critic_critic_opt_critic_opt_grad_overflow [1m0[22m [34m/[39m train/extr_critic_critic_opt_critic_opt_grad_scale [1m1e4[22m [34m/
train/extr_critic_critic_opt_grad_norm [1m2.02[22m [34m/[39m train/extr_critic_critic_opt_grad_steps [1m920[22m [34m/[39m train/extr_critic_critic_opt_loss [1m1.7e4[22m [34m/[39m train/extr_critic_mag [1m0.95[22m [34m/
train/extr_critic_max [1m0.95[22m [34m/[39m train/extr_critic_mean [1m0.21[22m [34m/[39m train/extr_critic_min [1m-0.04[22m [34m/[39m train/extr_critic_std [1m0.25[22m [34m/[39m train/extr_return_normed_mag [1m4.73[22m [34m/
train/extr_return_normed_max [1m4.73[22m [34m/[39m train/extr_return_normed_mean [1m0.27[22m [34m/[39m train/extr_return_normed_min [1m-0.78[22m [34m/[39m train/extr_return_normed_std [1m0.46[22m [34m/[39m train/extr_return_rate [1m0.14[22m [34m/
train/extr_return_raw_mag [1m7.83[22m [34m/[39m train/extr_return_raw_max [1m7.83[22m [34m/[39m train/extr_return_raw_mean [1m0.31[22m [34m/[39m train/extr_return_raw_min [1m-1.44[22m [34m/[39m train/extr_return_raw_std [1m0.78[22m [34m/
train/extr_reward_mag [1m0.99[22m [34m/[39m train/extr_reward_max [1m0.99[22m [34m/[39m train/extr_reward_mean [1m0.03[22m [34m/[39m train/extr_reward_min [1m-0.54[22m [34m/[39m train/extr_reward_std [1m0.15[22m [34m/[39m train/image_loss_mean [1m18.05[22m [34m/
train/image_loss_std [1m12.48[22m [34m/[39m train/model_loss_mean [1m20.56[22m [34m/[39m train/model_loss_std [1m14.49[22m [34m/[39m train/model_opt_grad_norm [1m132.5[22m [34m/[39m train/model_opt_grad_steps [1m910[22m [34m/[39m train/model_opt_loss
[1m253.17[22m [34m/[39m train/model_opt_model_opt_grad_overflow [1m0[22m [34m/[39m train/model_opt_model_opt_grad_scale [1m13.22[22m [34m/[39m train/policy_entropy_mag [1m0.13[22m [34m/[39m train/policy_entropy_max [1m0.13[22m [34m/
train/policy_entropy_mean [1m0.08[22m [34m/[39m train/policy_entropy_min [1m0.08[22m [34m/[39m train/policy_entropy_std [1m1.7e-3[22m [34m/[39m train/policy_logprob_mag [1m7.44[22m [34m/[39m train/policy_logprob_max [1m-9.5e-3[22m [34m/
train/policy_logprob_mean [1m-0.08[22m [34m/[39m train/policy_logprob_min [1m-7.44[22m [34m/[39m train/policy_logprob_std [1m0.72[22m [34m/[39m train/policy_randomness_mag [1m0.04[22m [34m/[39m train/policy_randomness_max [1m0.04[22m [34m/
train/policy_randomness_mean [1m0.03[22m [34m/[39m train/policy_randomness_min [1m0.03[22m [34m/[39m train/policy_randomness_std [1m6.1e-4[22m [34m/[39m train/post_ent_mag [1m42.41[22m [34m/[39m train/post_ent_max [1m42.41[22m [34m/
train/post_ent_mean [1m26.14[22m [34m/[39m train/post_ent_min [1m12.89[22m [34m/[39m train/post_ent_std [1m5.24[22m [34m/[39m train/prior_ent_mag [1m58.59[22m [34m/[39m train/prior_ent_max [1m58.59[22m [34m/[39m train/prior_ent_mean [1m30.95[22m [34m/
train/prior_ent_min [1m14.26[22m [34m/[39m train/prior_ent_std [1m7.34[22m [34m/[39m train/rep_loss_mean [1m4.01[22m [34m/[39m train/rep_loss_std [1m5.64[22m [34m/[39m train/reward_avg [1m5.9e-3[22m [34m/[39m train/reward_loss_mean [1m0.09[22m [34m/
train/reward_loss_std [1m0.38[22m [34m/[39m train/reward_max_data [1m1[22m [34m/[39m train/reward_max_pred [1m0.99[22m [34m/[39m train/reward_neg_acc [1m1[22m [34m/[39m train/reward_neg_loss [1m0.08[22m [34m/[39m train/reward_pos_acc [1m0.93[22m [34m/
train/reward_pos_loss [1m1.11[22m [34m/[39m train/reward_pred [1m5.7e-3[22m [34m/[39m train/reward_rate [1m0.01[22m [34m/[39m train/transition_tokens_loss_mean [1m0.01[22m [34m/[39m train/transition_tokens_loss_std [1m4.3e-3[22m [34m/
train_stats/sum_log_reward [1m0.43[22m [34m/[39m train_stats/max_log_achievement_collect_drink [1m0[22m [34m/[39m train_stats/max_log_achievement_collect_sapling [1m20[22m [34m/
train_stats/max_log_achievement_collect_wood [1m0[22m [34m/[39m train_stats/max_log_achievement_place_plant [1m0[22m [34m/[39m train_stats/max_log_achievement_wake_up [1m0.17[22m [34m/[39m train_stats/mean_log_entropy [1m0.08
[34m/[39m train_stats/max_log_achievement_defeat_zombie [1m0.33[22m [34m/[39m report/cont_avg [1m1[22m [34m/[39m report/cont_loss_mean [1m0.01[22m [34m/[39m report/cont_loss_std [1m0.12[22m [34m/[39m report/cont_neg_acc [1m0.4[22m [34m/[39m report/cont_neg_loss
[1m1.26[22m [34m/[39m report/cont_pos_acc [1m1[22m [34m/[39m report/cont_pos_loss [1m4.4e-3[22m [34m/[39m report/cont_pred [1m0.99[22m [34m/[39m report/cont_rate [1m1[22m [34m/[39m report/dyn_loss_mean [1m3.47[22m [34m/[39m report/dyn_loss_std [1m5.53[22m [34m/
report/image_loss_mean [1m13.27[22m [34m/[39m report/image_loss_std [1m9.98[22m [34m/[39m report/model_loss_mean [1m15.42[22m [34m/[39m report/model_loss_std [1m11.95[22m [34m/[39m report/post_ent_mag [1m36.38[22m [34m/[39m report/post_ent_max [1m36.38[22m [34m/
report/post_ent_mean [1m25.47[22m [34m/[39m report/post_ent_min [1m10.25[22m [34m/[39m report/post_ent_std [1m5.23[22m [34m/[39m report/prior_ent_mag [1m60.21[22m [34m/[39m report/prior_ent_max [1m60.21[22m [34m/[39m report/prior_ent_mean [1m30.36[22m [34m/
report/prior_ent_min [1m14.37[22m [34m/[39m report/prior_ent_std [1m7.42[22m [34m/[39m report/rep_loss_mean [1m3.47[22m [34m/[39m report/rep_loss_std [1m5.53[22m [34m/[39m report/reward_avg [1m3.8e-3[22m [34m/[39m report/reward_loss_mean [1m0.06[22m [34m/
report/reward_loss_std [1m0.27[22m [34m/[39m report/reward_max_data [1m1[22m [34m/[39m report/reward_max_pred [1m0.99[22m [34m/[39m report/reward_neg_acc [1m1[22m [34m/[39m report/reward_neg_loss [1m0.05[22m [34m/[39m report/reward_pos_acc [1m1[22m [34m/
report/reward_pos_loss [1m0.69[22m [34m/[39m report/reward_pred [1m3.4e-3[22m [34m/[39m report/reward_rate [1m7.8e-3[22m [34m/[39m report/transition_tokens_loss_mean [1m5.9e-3[22m [34m/[39m report/transition_tokens_loss_std [1m2.7e-3[22m [34m/
eval/cont_avg [1m1[22m [34m/[39m eval/cont_loss_mean [1m0.02[22m [34m/[39m eval/cont_loss_std [1m0.37[22m [34m/[39m eval/cont_neg_acc [1m0[22m [34m/[39m eval/cont_neg_loss [1m5.38[22m [34m/[39m eval/cont_pos_acc [1m1[22m [34m/[39m eval/cont_pos_loss [1m2.7e-4[22m [34m/
eval/cont_pred [1m1[22m [34m/[39m eval/cont_rate [1m1[22m [34m/[39m eval/dyn_loss_mean [1m12.23[22m [34m/[39m eval/dyn_loss_std [1m8.32[22m [34m/[39m eval/image_loss_mean [1m57.92[22m [34m/[39m eval/image_loss_std [1m63.58[22m [34m/[39m eval/model_loss_mean [1m65.41[22m [34m/
eval/model_loss_std [1m66.4[22m [34m/[39m eval/post_ent_mag [1m53.58[22m [34m/[39m eval/post_ent_max [1m53.58[22m [34m/[39m eval/post_ent_mean [1m28.62[22m [34m/[39m eval/post_ent_min [1m9.56[22m [34m/[39m eval/post_ent_std [1m8.28[22m [34m/[39m eval/prior_ent_mag
[1m60.21[22m [34m/[39m eval/prior_ent_max [1m60.21[22m [34m/[39m eval/prior_ent_mean [1m32.63[22m [34m/[39m eval/prior_ent_min [1m13.5[22m [34m/[39m eval/prior_ent_std [1m8.27[22m [34m/[39m eval/rep_loss_mean [1m12.23[22m [34m/[39m eval/rep_loss_std [1m8.32[22m [34m/
eval/reward_avg [1m8.9e-3[22m [34m/[39m eval/reward_loss_mean [1m0.12[22m [34m/[39m eval/reward_loss_std [1m0.91[22m [34m/[39m eval/reward_max_data [1m1[22m [34m/[39m eval/reward_max_pred [1m0.97[22m [34m/[39m eval/reward_neg_acc [1m1[22m [34m/
eval/reward_neg_loss [1m0.07[22m [34m/[39m eval/reward_pos_acc [1m0.33[22m [34m/[39m eval/reward_pos_loss [1m4.78[22m [34m/[39m eval/reward_pred [1m2.8e-3[22m [34m/[39m eval/reward_rate [1m0.01[22m [34m/[39m eval/transition_tokens_loss_mean [1m7.1e-3[22m [34m/
eval/transition_tokens_loss_std [1m2.2e-3[22m [34m/[39m replay/size [1m3530[22m [34m/[39m replay/inserts [1m1300[22m [34m/[39m replay/samples [1m1e4[22m [34m/[39m replay/insert_wait_avg [1m3.7e-6[22m [34m/[39m replay/insert_wait_frac [1m1[22m [34m/
replay/sample_wait_avg [1m1.1e-6[22m [34m/[39m replay/sample_wait_frac [1m1[22m [34m/[39m eval_replay/size [1m1227[22m [34m/[39m eval_replay/inserts [1m0[22m [34m/[39m eval_replay/samples [1m16[22m [34m/[39m eval_replay/insert_wait_avg nan [34m/
eval_replay/insert_wait_frac nan [34m/[39m eval_replay/sample_wait_avg [1m1.5e-6[22m [34m/[39m eval_replay/sample_wait_frac [1m1[22m [34m/[39m timer/duration [1m300.18[22m [34m/[39m timer/env.step_count [1m1300[22m [34m/[39m timer/env.step_total
[1m12.62[22m [34m/[39m timer/env.step_frac [1m0.04[22m [34m/[39m timer/env.step_avg [1m9.7e-3[22m [34m/[39m timer/env.step_min [1m2.4e-3[22m [34m/[39m timer/env.step_max [1m1.42[22m [34m/[39m timer/replay._sample_count [1m1e4[22m [34m/[39m timer/replay._sample_total
[1m570.4[22m [34m/[39m timer/replay._sample_frac [1m1.9[22m [34m/[39m timer/replay._sample_avg [1m0.05[22m [34m/[39m timer/replay._sample_min [1m8.2e-4[22m [34m/[39m timer/replay._sample_max [1m0.12[22m [34m/[39m timer/agent.save_count [1m0[22m [34m/
timer/agent.save_total [1m0[22m [34m/[39m timer/agent.save_frac [1m0[22m [34m/[39m timer/agent.policy_count [1m1300[22m [34m/[39m timer/agent.policy_total [1m12.88[22m [34m/[39m timer/agent.policy_frac [1m0.04[22m [34m/[39m timer/agent.policy_avg [1m9.9e-3
[34m/[39m timer/agent.policy_min [1m8.3e-3[22m [34m/[39m timer/agent.policy_max [1m0.03[22m [34m/[39m timer/dataset_train_count [1m650[22m [34m/[39m timer/dataset_train_total [1m0.09[22m [34m/[39m timer/dataset_train_frac [1m3.1e-4[22m [34m/
timer/dataset_train_avg [1m1.4e-4[22m [34m/[39m timer/dataset_train_min [1m1.2e-4[22m [34m/[39m timer/dataset_train_max [1m1.8e-3[22m [34m/[39m timer/agent.train_count [1m650[22m [34m/[39m timer/agent.train_total [1m256.11[22m [34m/
timer/agent.train_frac [1m0.85[22m [34m/[39m timer/agent.train_avg [1m0.39[22m [34m/[39m timer/agent.train_min [1m0.39[22m [34m/[39m timer/agent.train_max [1m0.42[22m [34m/[39m timer/agent.report_count [1m2[22m [34m/[39m timer/agent.report_total [1m0.45[22m [34m/
timer/agent.report_frac [1m1.5e-3[22m [34m/[39m timer/agent.report_avg [1m0.23[22m [34m/[39m timer/agent.report_min [1m0.23[22m [34m/[39m timer/agent.report_max [1m0.23[22m [34m/[39m timer/dataset_eval_count [1m1[22m [34m/[39m timer/dataset_eval_total
[1m4.8e-5[22m [34m/[39m timer/dataset_eval_frac [1m1.6e-7[22m [34m/[39m timer/dataset_eval_avg [1m4.8e-5[22m [34m/[39m timer/dataset_eval_min [1m4.8e-5[22m [34m/[39m timer/dataset_eval_max [1m4.8e-5[22m [34m/[39m fps [1m4.33
Episode has 119 steps and return 1.1.
Episode has 190 steps and return 0.1.
Episode has 153 steps and return 0.1.
Saved chunk: 20240102T015114F155001-3Z1hYgFS9wWbFolf4ikosX-1gehyYKQSUsM0nHAjByia8-1024.npz
Episode has 198 steps and return 1.1.
Episode has 190 steps and return 2.1.
Writing checkpoint: /home/ziyu/logdir/ziyu_crafter_cuda_0_seed_0/checkpoint.ckpt
Saved chunk: 20240102T014122F279102-5LjyZVTTm8nIvxVpKFaaYe-0000000000000000000000-266.npz
Saved chunk: 20240102T015512F395069-1gehyYKQSUsM0nHAjByia8-0000000000000000000000-404.npz
Wrote checkpoint: /home/ziyu/logdir/ziyu_crafter_cuda_0_seed_0/checkpoint.ckpt
Episode has 138 steps and return 0.1.
Episode has 216 steps and return 0.1.
[92mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [39m[1mStep 4873[92m[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
episode/length [1m216[22m [34m/[39m episode/score [1m0.1[22m [34m/[39m episode/reward_rate [1m1[22m [34m/[39m train/action_mag [1m16[22m [34m/[39m train/action_max [1m16[22m [34m/[39m train/action_mean [1m5.03[22m [34m/[39m train/action_min [1m0[22m [34m/[39m train/action_std [1m0.58[22m [34m/
train/actor_opt_actor_opt_grad_overflow [1m0[22m [34m/[39m train/actor_opt_actor_opt_grad_scale [1m1e4[22m [34m/[39m train/actor_opt_grad_norm [1m7.5e-4[22m [34m/[39m train/actor_opt_grad_steps [1m1565[22m [34m/[39m train/actor_opt_loss
[1m0.2[22m [34m/[39m train/adv_mag [1m2.73[22m [34m/[39m train/adv_max [1m2.73[22m [34m/[39m train/adv_mean [1m5.7e-3[22m [34m/[39m train/adv_min [1m-1.02[22m [34m/[39m train/adv_std [1m0.2[22m [34m/[39m train/cont_avg [1m0.99[22m [34m/[39m train/cont_loss_mean [1m4e-3[22m [34m/
train/cont_loss_std [1m0.07[22m [34m/[39m train/cont_neg_acc [1m0.86[22m [34m/[39m train/cont_neg_loss [1m0.47[22m [34m/[39m train/cont_pos_acc [1m1[22m [34m/[39m train/cont_pos_loss [1m1.4e-3[22m [34m/[39m train/cont_pred [1m0.99[22m [34m/[39m train/cont_rate [1m0.99[22m [34m/
train/dyn_loss_mean [1m3.67[22m [34m/[39m train/dyn_loss_std [1m5.39[22m [34m/[39m train/extr_critic_critic_opt_critic_opt_grad_overflow [1m0[22m [34m/[39m train/extr_critic_critic_opt_critic_opt_grad_scale [1m1e4[22m [34m/
train/extr_critic_critic_opt_grad_norm [1m1.17[22m [34m/[39m train/extr_critic_critic_opt_grad_steps [1m1565[22m [34m/[39m train/extr_critic_critic_opt_loss [1m1.5e4[22m [34m/[39m train/extr_critic_mag [1m2.26[22m [34m/
train/extr_critic_max [1m2.26[22m [34m/[39m train/extr_critic_mean [1m0.05[22m [34m/[39m train/extr_critic_min [1m-0.46[22m [34m/[39m train/extr_critic_std [1m0.45[22m [34m/[39m train/extr_return_normed_mag [1m4.16[22m [34m/
train/extr_return_normed_max [1m4.16[22m [34m/[39m train/extr_return_normed_mean [1m0.3[22m [34m/[39m train/extr_return_normed_min [1m-0.66[22m [34m/[39m train/extr_return_normed_std [1m0.4[22m [34m/[39m train/extr_return_rate [1m0.14[22m [34m/
train/extr_return_raw_mag [1m6.65[22m [34m/[39m train/extr_return_raw_max [1m6.65[22m [34m/[39m train/extr_return_raw_mean [1m0.06[22m [34m/[39m train/extr_return_raw_min [1m-1.59[22m [34m/[39m train/extr_return_raw_std [1m0.68[22m [34m/
train/extr_reward_mag [1m1[22m [34m/[39m train/extr_reward_max [1m1[22m [34m/[39m train/extr_reward_mean [1m9e-3[22m [34m/[39m train/extr_reward_min [1m-0.53[22m [34m/[39m train/extr_reward_std [1m0.12[22m [34m/[39m train/image_loss_mean [1m9.14[22m [34m/
train/image_loss_std [1m7.63[22m [34m/[39m train/model_loss_mean [1m11.4[22m [34m/[39m train/model_loss_std [1m9.65[22m [34m/[39m train/model_opt_grad_norm [1m122.39[22m [34m/[39m train/model_opt_grad_steps [1m1555[22m [34m/[39m train/model_opt_loss
[1m222.73[22m [34m/[39m train/model_opt_model_opt_grad_overflow [1m0[22m [34m/[39m train/model_opt_model_opt_grad_scale [1m19.53[22m [34m/[39m train/policy_entropy_mag [1m0.25[22m [34m/[39m train/policy_entropy_max [1m0.25[22m [34m/
train/policy_entropy_mean [1m0.08[22m [34m/[39m train/policy_entropy_min [1m0.08[22m [34m/[39m train/policy_entropy_std [1m6e-3[22m [34m/[39m train/policy_logprob_mag [1m7.44[22m [34m/[39m train/policy_logprob_max [1m-9.5e-3[22m [34m/
train/policy_logprob_mean [1m-0.08[22m [34m/[39m train/policy_logprob_min [1m-7.44[22m [34m/[39m train/policy_logprob_std [1m0.72[22m [34m/[39m train/policy_randomness_mag [1m0.09[22m [34m/[39m train/policy_randomness_max [1m0.09[22m [34m/
train/policy_randomness_mean [1m0.03[22m [34m/[39m train/policy_randomness_min [1m0.03[22m [34m/[39m train/policy_randomness_std [1m2.1e-3[22m [34m/[39m train/post_ent_mag [1m37.88[22m [34m/[39m train/post_ent_max [1m37.88[22m [34m/
train/post_ent_mean [1m24.87[22m [34m/[39m train/post_ent_min [1m11.22[22m [34m/[39m train/post_ent_std [1m4.67[22m [34m/[39m train/prior_ent_mag [1m55.78[22m [34m/[39m train/prior_ent_max [1m55.78[22m [34m/[39m train/prior_ent_mean [1m29.16[22m [34m/
train/prior_ent_min [1m13.8[22m [34m/[39m train/prior_ent_std [1m6.54[22m [34m/[39m train/rep_loss_mean [1m3.67[22m [34m/[39m train/rep_loss_std [1m5.39[22m [34m/[39m train/reward_avg [1m4.2e-3[22m [34m/[39m train/reward_loss_mean [1m0.06[22m [34m/
train/reward_loss_std [1m0.29[22m [34m/[39m train/reward_max_data [1m1[22m [34m/[39m train/reward_max_pred [1m1[22m [34m/[39m train/reward_neg_acc [1m1[22m [34m/[39m train/reward_neg_loss [1m0.05[22m [34m/[39m train/reward_pos_acc [1m0.95[22m [34m/
train/reward_pos_loss [1m0.96[22m [34m/[39m train/reward_pred [1m4.1e-3[22m [34m/[39m train/reward_rate [1m9.5e-3[22m [34m/[39m train/transition_tokens_loss_mean [1m4.2e-3[22m [34m/[39m train/transition_tokens_loss_std [1m1.6e-3[22m [34m/
train_stats/sum_log_reward [1m0.67[22m [34m/[39m train_stats/max_log_achievement_collect_drink [1m0[22m [34m/[39m train_stats/max_log_achievement_collect_sapling [1m15.14[22m [34m/
train_stats/max_log_achievement_collect_wood [1m0[22m [34m/[39m train_stats/max_log_achievement_defeat_zombie [1m0.14[22m [34m/[39m train_stats/max_log_achievement_place_plant [1m0.14[22m [34m/
train_stats/max_log_achievement_wake_up [1m0[22m [34m/[39m train_stats/mean_log_entropy [1m0.08[22m [34m/[39m train_stats/max_log_achievement_eat_cow [1m0.5[22m [34m/[39m report/cont_avg [1m0.99[22m [34m/[39m report/cont_loss_mean [1m4e-4[22m [34m/
report/cont_loss_std [1m8.4e-3[22m [34m/[39m report/cont_neg_acc [1m1[22m [34m/[39m report/cont_neg_loss [1m0.04[22m [34m/[39m report/cont_pos_acc [1m1[22m [34m/[39m report/cont_pos_loss [1m1.3e-4[22m [34m/[39m report/cont_pred [1m0.99[22m [34m/[39m report/cont_rate
[1m0.99[22m [34m/[39m report/dyn_loss_mean [1m3.25[22m [34m/[39m report/dyn_loss_std [1m6.47[22m [34m/[39m report/image_loss_mean [1m7.66[22m [34m/[39m report/image_loss_std [1m7.4[22m [34m/[39m report/model_loss_mean [1m9.64[22m [34m/[39m report/model_loss_std [1m10.01
[34m/[39m report/post_ent_mag [1m35.9[22m [34m/[39m report/post_ent_max [1m35.9[22m [34m/[39m report/post_ent_mean [1m23.08[22m [34m/[39m report/post_ent_min [1m9.97[22m [34m/[39m report/post_ent_std [1m4.37[22m [34m/[39m report/prior_ent_mag [1m53.37[22m [34m/
report/prior_ent_max [1m53.37[22m [34m/[39m report/prior_ent_mean [1m26.41[22m [34m/[39m report/prior_ent_min [1m12.18[22m [34m/[39m report/prior_ent_std [1m6.25[22m [34m/[39m report/rep_loss_mean [1m3.25[22m [34m/[39m report/rep_loss_std [1m6.47[22m [34m/
report/reward_avg [1m7.5e-3[22m [34m/[39m report/reward_loss_mean [1m0.03[22m [34m/[39m report/reward_loss_std [1m0.13[22m [34m/[39m report/reward_max_data [1m1[22m [34m/[39m report/reward_max_pred [1m1[22m [34m/[39m report/reward_neg_acc [1m1[22m [34m/
report/reward_neg_loss [1m0.02[22m [34m/[39m report/reward_pos_acc [1m1[22m [34m/[39m report/reward_pos_loss [1m0.69[22m [34m/[39m report/reward_pred [1m7.4e-3[22m [34m/[39m report/reward_rate [1m0.01[22m [34m/[39m report/transition_tokens_loss_mean
[1m3.3e-3[22m [34m/[39m report/transition_tokens_loss_std [1m1.3e-3[22m [34m/[39m eval/cont_avg [1m1[22m [34m/[39m eval/cont_loss_mean [1m0.02[22m [34m/[39m eval/cont_loss_std [1m0.34[22m [34m/[39m eval/cont_neg_acc [1m0.2[22m [34m/[39m eval/cont_neg_loss [1m3.47[22m [34m/
eval/cont_pos_acc [1m1[22m [34m/[39m eval/cont_pos_loss [1m1.8e-4[22m [34m/[39m eval/cont_pred [1m1[22m [34m/[39m eval/cont_rate [1m1[22m [34m/[39m eval/dyn_loss_mean [1m16.59[22m [34m/[39m eval/dyn_loss_std [1m11.16[22m [34m/[39m eval/image_loss_mean [1m84.82[22m [34m/
eval/image_loss_std [1m94.53[22m [34m/[39m eval/model_loss_mean [1m94.97[22m [34m/[39m eval/model_loss_std [1m98.18[22m [34m/[39m eval/post_ent_mag [1m50.79[22m [34m/[39m eval/post_ent_max [1m50.79[22m [34m/[39m eval/post_ent_mean [1m29.3[22m [34m/
eval/post_ent_min [1m10.26[22m [34m/[39m eval/post_ent_std [1m8.46[22m [34m/[39m eval/prior_ent_mag [1m53.37[22m [34m/[39m eval/prior_ent_max [1m53.37[22m [34m/[39m eval/prior_ent_mean [1m31.55[22m [34m/[39m eval/prior_ent_min [1m12.65[22m [34m/[39m eval/prior_ent_std
[1m7.83[22m [34m/[39m eval/rep_loss_mean [1m16.59[22m [34m/[39m eval/rep_loss_std [1m11.16[22m [34m/[39m eval/reward_avg [1m0.01[22m [34m/[39m eval/reward_loss_mean [1m0.17[22m [34m/[39m eval/reward_loss_std [1m1.12[22m [34m/[39m eval/reward_max_data [1m1[22m [34m/
eval/reward_max_pred [1m0.99[22m [34m/[39m eval/reward_neg_acc [1m1[22m [34m/[39m eval/reward_neg_loss [1m0.08[22m [34m/[39m eval/reward_pos_acc [1m0.42[22m [34m/[39m eval/reward_pos_loss [1m5.26[22m [34m/[39m eval/reward_pred [1m5e-3[22m [34m/[39m eval/reward_rate
[1m0.02[22m [34m/[39m eval/transition_tokens_loss_mean [1m4.2e-3[22m [34m/[39m eval/transition_tokens_loss_std [1m1.2e-3[22m [34m/[39m replay/size [1m4810[22m [34m/[39m replay/inserts [1m1280[22m [34m/[39m replay/samples [1m1e4[22m [34m/[39m replay/insert_wait_avg
[1m3.6e-6[22m [34m/[39m replay/insert_wait_frac [1m1[22m [34m/[39m replay/sample_wait_avg [1m1.2e-6[22m [34m/[39m replay/sample_wait_frac [1m1[22m [34m/[39m eval_replay/size [1m1227[22m [34m/[39m eval_replay/inserts [1m0[22m [34m/[39m eval_replay/samples [1m16[22m [34m/
eval_replay/insert_wait_avg nan [34m/[39m eval_replay/insert_wait_frac nan [34m/[39m eval_replay/sample_wait_avg [1m1.5e-6[22m [34m/[39m eval_replay/sample_wait_frac [1m1[22m [34m/[39m timer/duration [1m300.36[22m [34m/
timer/env.step_count [1m1280[22m [34m/[39m timer/env.step_total [1m14.17[22m [34m/[39m timer/env.step_frac [1m0.05[22m [34m/[39m timer/env.step_avg [1m0.01[22m [34m/[39m timer/env.step_min [1m2.6e-3[22m [34m/[39m timer/env.step_max [1m1.4[22m [34m/
timer/replay._sample_count [1m1e4[22m [34m/[39m timer/replay._sample_total [1m564.36[22m [34m/[39m timer/replay._sample_frac [1m1.88[22m [34m/[39m timer/replay._sample_avg [1m0.06[22m [34m/[39m timer/replay._sample_min [1m3.5e-3[22m [34m/
timer/replay._sample_max [1m0.21[22m [34m/[39m timer/agent.save_count [1m1[22m [34m/[39m timer/agent.save_total [1m0.97[22m [34m/[39m timer/agent.save_frac [1m3.2e-3[22m [34m/[39m timer/agent.save_avg [1m0.97[22m [34m/[39m timer/agent.save_min [1m0.97[22m [34m/
timer/agent.save_max [1m0.97[22m [34m/[39m timer/agent.policy_count [1m1280[22m [34m/[39m timer/agent.policy_total [1m15.5[22m [34m/[39m timer/agent.policy_frac [1m0.05[22m [34m/[39m timer/agent.policy_avg [1m0.01[22m [34m/[39m timer/agent.policy_min
[1m8.2e-3[22m [34m/[39m timer/agent.policy_max [1m1.67[22m [34m/[39m timer/dataset_train_count [1m640[22m [34m/[39m timer/dataset_train_total [1m0.09[22m [34m/[39m timer/dataset_train_frac [1m3e-4[22m [34m/[39m timer/dataset_train_avg [1m1.4e-4[22m [34m/
timer/dataset_train_min [1m1.2e-4[22m [34m/[39m timer/dataset_train_max [1m3.5e-4[22m [34m/[39m timer/agent.train_count [1m640[22m [34m/[39m timer/agent.train_total [1m252.14[22m [34m/[39m timer/agent.train_frac [1m0.84[22m [34m/
timer/agent.train_avg [1m0.39[22m [34m/[39m timer/agent.train_min [1m0.39[22m [34m/[39m timer/agent.train_max [1m0.42[22m [34m/[39m timer/agent.report_count [1m2[22m [34m/[39m timer/agent.report_total [1m0.45[22m [34m/[39m timer/agent.report_frac [1m1.5e-3
[34m/[39m timer/agent.report_avg [1m0.23[22m [34m/[39m timer/agent.report_min [1m0.22[22m [34m/[39m timer/agent.report_max [1m0.23[22m [34m/[39m timer/dataset_eval_count [1m1[22m [34m/[39m timer/dataset_eval_total [1m7.8e-5[22m [34m/[39m timer/dataset_eval_frac
[1m2.6e-7[22m [34m/[39m timer/dataset_eval_avg [1m7.8e-5[22m [34m/[39m timer/dataset_eval_min [1m7.8e-5[22m [34m/[39m timer/dataset_eval_max [1m7.8e-5[22m [34m/[39m fps [1m4.26
Episode has 227 steps and return 0.1.
Saved chunk: 20240102T015512F395069-1gehyYKQSUsM0nHAjByia8-3k3Dp2xtinisiNZsUuK4Eq-1024.npz
Episode has 168 steps and return 0.1.
Episode has 143 steps and return 0.1.
Episode has 212 steps and return 1.1.
Episode has 220 steps and return 0.1.
Episode has 75 steps and return 0.1.
Episode has 265 steps and return 0.1.
Saved chunk: 20240102T015912F557556-3k3Dp2xtinisiNZsUuK4Eq-0nHtZd7nwlZHm0X7ZLgSSC-1024.npz
[92mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [39m[1mStep 6167[92m[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
episode/length [1m265[22m [34m/[39m episode/score [1m0.1[22m [34m/[39m episode/reward_rate [1m0.98[22m [34m/[39m train/action_mag [1m16[22m [34m/[39m train/action_max [1m16[22m [34m/[39m train/action_mean [1m5.25[22m [34m/[39m train/action_min [1m0[22m [34m/[39m train/action_std
[1m2.44[22m [34m/[39m train/actor_opt_actor_opt_grad_overflow [1m0[22m [34m/[39m train/actor_opt_actor_opt_grad_scale [1m1e4[22m [34m/[39m train/actor_opt_grad_norm [1m0.04[22m [34m/[39m train/actor_opt_grad_steps [1m2210[22m [34m/
train/actor_opt_loss [1m105.37[22m [34m/[39m train/adv_mag [1m2.03[22m [34m/[39m train/adv_max [1m2.02[22m [34m/[39m train/adv_mean [1m0.05[22m [34m/[39m train/adv_min [1m-0.84[22m [34m/[39m train/adv_std [1m0.18[22m [34m/[39m train/cont_avg [1m0.99[22m [34m/
train/cont_loss_mean [1m2.2e-3[22m [34m/[39m train/cont_loss_std [1m0.05[22m [34m/[39m train/cont_neg_acc [1m0.95[22m [34m/[39m train/cont_neg_loss [1m0.2[22m [34m/[39m train/cont_pos_acc [1m1[22m [34m/[39m train/cont_pos_loss [1m1e-3[22m [34m/[39m train/cont_pred
[1m0.99[22m [34m/[39m train/cont_rate [1m0.99[22m [34m/[39m train/dyn_loss_mean [1m3.72[22m [34m/[39m train/dyn_loss_std [1m5.48[22m [34m/[39m train/extr_critic_critic_opt_critic_opt_grad_overflow [1m0[22m [34m/
train/extr_critic_critic_opt_critic_opt_grad_scale [1m1e4[22m [34m/[39m train/extr_critic_critic_opt_grad_norm [1m1.61[22m [34m/[39m train/extr_critic_critic_opt_grad_steps [1m2210[22m [34m/
train/extr_critic_critic_opt_loss [1m2e4[22m [34m/[39m train/extr_critic_mag [1m2.59[22m [34m/[39m train/extr_critic_max [1m2.59[22m [34m/[39m train/extr_critic_mean [1m0.59[22m [34m/[39m train/extr_critic_min [1m-0.34[22m [34m/
train/extr_critic_std [1m0.56[22m [34m/[39m train/extr_return_normed_mag [1m3.16[22m [34m/[39m train/extr_return_normed_max [1m3.16[22m [34m/[39m train/extr_return_normed_mean [1m0.49[22m [34m/[39m train/extr_return_normed_min [1m-0.44[22m [34m/
train/extr_return_normed_std [1m0.37[22m [34m/[39m train/extr_return_rate [1m0.55[22m [34m/[39m train/extr_return_raw_mag [1m5.61[22m [34m/[39m train/extr_return_raw_max [1m5.61[22m [34m/[39m train/extr_return_raw_mean [1m0.68[22m [34m/
train/extr_return_raw_min [1m-1.12[22m [34m/[39m train/extr_return_raw_std [1m0.72[22m [34m/[39m train/extr_reward_mag [1m1[22m [34m/[39m train/extr_reward_max [1m1[22m [34m/[39m train/extr_reward_mean [1m9.9e-3[22m [34m/[39m train/extr_reward_min [1m-0.49
[34m/[39m train/extr_reward_std [1m0.12[22m [34m/[39m train/image_loss_mean [1m8.9[22m [34m/[39m train/image_loss_std [1m9.26[22m [34m/[39m train/model_loss_mean [1m11.17[22m [34m/[39m train/model_loss_std [1m11.12[22m [34m/[39m train/model_opt_grad_norm [1m148.78
[34m/[39m train/model_opt_grad_steps [1m2200[22m [34m/[39m train/model_opt_loss [1m399.15[22m [34m/[39m train/model_opt_model_opt_grad_overflow [1m0[22m [34m/[39m train/model_opt_model_opt_grad_scale [1m35.16[22m [34m/
train/policy_entropy_mag [1m1.83[22m [34m/[39m train/policy_entropy_max [1m1.83[22m [34m/[39m train/policy_entropy_mean [1m0.26[22m [34m/[39m train/policy_entropy_min [1m0.08[22m [34m/[39m train/policy_entropy_std [1m0.27[22m [34m/
train/policy_logprob_mag [1m7.44[22m [34m/[39m train/policy_logprob_max [1m-9.5e-3[22m [34m/[39m train/policy_logprob_mean [1m-0.26[22m [34m/[39m train/policy_logprob_min [1m-7.44[22m [34m/[39m train/policy_logprob_std [1m0.9[22m [34m/
train/policy_randomness_mag [1m0.65[22m [34m/[39m train/policy_randomness_max [1m0.65[22m [34m/[39m train/policy_randomness_mean [1m0.09[22m [34m/[39m train/policy_randomness_min [1m0.03[22m [34m/[39m train/policy_randomness_std [1m0.09[22m [34m/
train/post_ent_mag [1m36.45[22m [34m/[39m train/post_ent_max [1m36.45[22m [34m/[39m train/post_ent_mean [1m24.58[22m [34m/[39m train/post_ent_min [1m10.87[22m [34m/[39m train/post_ent_std [1m4.44[22m [34m/[39m train/prior_ent_mag [1m55.77[22m [34m/
train/prior_ent_max [1m55.77[22m [34m/[39m train/prior_ent_mean [1m28.6[22m [34m/[39m train/prior_ent_min [1m13.18[22m [34m/[39m train/prior_ent_std [1m6.48[22m [34m/[39m train/rep_loss_mean [1m3.72[22m [34m/[39m train/rep_loss_std [1m5.48[22m [34m/
train/reward_avg [1m4.6e-3[22m [34m/[39m train/reward_loss_mean [1m0.04[22m [34m/[39m train/reward_loss_std [1m0.22[22m [34m/[39m train/reward_max_data [1m1[22m [34m/[39m train/reward_max_pred [1m1[22m [34m/[39m train/reward_neg_acc [1m1[22m [34m/
train/reward_neg_loss [1m0.03[22m [34m/[39m train/reward_pos_acc [1m0.95[22m [34m/[39m train/reward_pos_loss [1m0.96[22m [34m/[39m train/reward_pred [1m4.3e-3[22m [34m/[39m train/reward_rate [1m9.7e-3[22m [34m/[39m train/transition_tokens_loss_mean
[1m2.7e-3[22m [34m/[39m train/transition_tokens_loss_std [1m1e-3[22m [34m/[39m train_stats/sum_log_reward [1m0.24[22m [34m/[39m train_stats/max_log_achievement_collect_drink [1m11[22m [34m/
train_stats/max_log_achievement_collect_sapling [1m5.86[22m [34m/[39m train_stats/max_log_achievement_collect_wood [1m0[22m [34m/[39m train_stats/max_log_achievement_defeat_zombie [1m0[22m [34m/
train_stats/max_log_achievement_eat_cow [1m0[22m [34m/[39m train_stats/max_log_achievement_place_plant [1m0[22m [34m/[39m train_stats/max_log_achievement_wake_up [1m1.29[22m [34m/[39m train_stats/mean_log_entropy [1m0.31[22m [34m/
report/cont_avg [1m1[22m [34m/[39m report/cont_loss_mean [1m4e-5[22m [34m/[39m report/cont_loss_std [1m7.9e-4[22m [34m/[39m report/cont_neg_acc [1m1[22m [34m/[39m report/cont_neg_loss [1m1.2e-3[22m [34m/[39m report/cont_pos_acc [1m1[22m [34m/[39m report/cont_pos_loss
[1m3.6e-5[22m [34m/[39m report/cont_pred [1m1[22m [34m/[39m report/cont_rate [1m1[22m [34m/[39m report/dyn_loss_mean [1m3.33[22m [34m/[39m report/dyn_loss_std [1m4.92[22m [34m/[39m report/image_loss_mean [1m6.16[22m [34m/[39m report/image_loss_std [1m5.01[22m [34m/
report/model_loss_mean [1m8.18[22m [34m/[39m report/model_loss_std [1m6.76[22m [34m/[39m report/post_ent_mag [1m34.23[22m [34m/[39m report/post_ent_max [1m34.23[22m [34m/[39m report/post_ent_mean [1m25.55[22m [34m/[39m report/post_ent_min [1m10.74[22m [34m/
report/post_ent_std [1m3.63[22m [34m/[39m report/prior_ent_mag [1m57.5[22m [34m/[39m report/prior_ent_max [1m57.5[22m [34m/[39m report/prior_ent_mean [1m28.58[22m [34m/[39m report/prior_ent_min [1m13.14[22m [34m/[39m report/prior_ent_std [1m5.67[22m [34m/
report/rep_loss_mean [1m3.33[22m [34m/[39m report/rep_loss_std [1m4.92[22m [34m/[39m report/reward_avg [1m4.3e-3[22m [34m/[39m report/reward_loss_mean [1m0.02[22m [34m/[39m report/reward_loss_std [1m0.13[22m [34m/[39m report/reward_max_data [1m1[22m [34m/
report/reward_max_pred [1m1[22m [34m/[39m report/reward_neg_acc [1m1[22m [34m/[39m report/reward_neg_loss [1m0.01[22m [34m/[39m report/reward_pos_acc [1m1[22m [34m/[39m report/reward_pos_loss [1m0.84[22m [34m/[39m report/reward_pred [1m3.7e-3[22m [34m/
report/reward_rate [1m7.8e-3[22m [34m/[39m report/transition_tokens_loss_mean [1m2e-3[22m [34m/[39m report/transition_tokens_loss_std [1m7e-4[22m [34m/[39m eval/cont_avg [1m1[22m [34m/[39m eval/cont_loss_mean [1m0.03[22m [34m/[39m eval/cont_loss_std
[1m0.54[22m [34m/[39m eval/cont_neg_acc [1m0.2[22m [34m/[39m eval/cont_neg_loss [1m6.42[22m [34m/[39m eval/cont_pos_acc [1m1[22m [34m/[39m eval/cont_pos_loss [1m8.1e-5[22m [34m/[39m eval/cont_pred [1m1[22m [34m/[39m eval/cont_rate [1m1[22m [34m/[39m eval/dyn_loss_mean [1m17.14[22m [34m/
eval/dyn_loss_std [1m10.44[22m [34m/[39m eval/image_loss_mean [1m53.36[22m [34m/[39m eval/image_loss_std [1m60.39[22m [34m/[39m eval/model_loss_mean [1m63.8[22m [34m/[39m eval/model_loss_std [1m63.56[22m [34m/[39m eval/post_ent_mag [1m51.96[22m [34m/
eval/post_ent_max [1m51.96[22m [34m/[39m eval/post_ent_mean [1m28.29[22m [34m/[39m eval/post_ent_min [1m11.13[22m [34m/[39m eval/post_ent_std [1m6.78[22m [34m/[39m eval/prior_ent_mag [1m57.5[22m [34m/[39m eval/prior_ent_max [1m57.5[22m [34m/[39m eval/prior_ent_mean
[1m32.65[22m [34m/[39m eval/prior_ent_min [1m12.99[22m [34m/[39m eval/prior_ent_std [1m7.86[22m [34m/[39m eval/rep_loss_mean [1m17.14[22m [34m/[39m eval/rep_loss_std [1m10.44[22m [34m/[39m eval/reward_avg [1m4.1e-3[22m [34m/[39m eval/reward_loss_mean [1m0.12[22m [34m/
eval/reward_loss_std [1m0.88[22m [34m/[39m eval/reward_max_data [1m1[22m [34m/[39m eval/reward_max_pred [1m1[22m [34m/[39m eval/reward_neg_acc [1m1[22m [34m/[39m eval/reward_neg_loss [1m0.08[22m [34m/[39m eval/reward_pos_acc [1m0.25[22m [34m/[39m eval/reward_pos_loss
[1m5.21[22m [34m/[39m eval/reward_pred [1m4.5e-3[22m [34m/[39m eval/reward_rate [1m7.8e-3[22m [34m/[39m eval/transition_tokens_loss_mean [1m2.7e-3[22m [34m/[39m eval/transition_tokens_loss_std [1m6.5e-4[22m [34m/[39m replay/size [1m6104[22m [34m/[39m replay/inserts
[1m1294[22m [34m/[39m replay/samples [1m1e4[22m [34m/[39m replay/insert_wait_avg [1m3.7e-6[22m [34m/[39m replay/insert_wait_frac [1m1[22m [34m/[39m replay/sample_wait_avg [1m1.3e-6[22m [34m/[39m replay/sample_wait_frac [1m1[22m [34m/[39m eval_replay/size [1m1227[22m [34m/
eval_replay/inserts [1m0[22m [34m/[39m eval_replay/samples [1m16[22m [34m/[39m eval_replay/insert_wait_avg nan [34m/[39m eval_replay/insert_wait_frac nan [34m/[39m eval_replay/sample_wait_avg [1m1.8e-6[22m [34m/
eval_replay/sample_wait_frac [1m1[22m [34m/[39m timer/duration [1m300.05[22m [34m/[39m timer/env.step_count [1m1294[22m [34m/[39m timer/env.step_total [1m13.77[22m [34m/[39m timer/env.step_frac [1m0.05[22m [34m/[39m timer/env.step_avg [1m0.01[22m [34m/
timer/env.step_min [1m2.5e-3[22m [34m/[39m timer/env.step_max [1m1.37[22m [34m/[39m timer/replay._sample_count [1m1e4[22m [34m/[39m timer/replay._sample_total [1m568.28[22m [34m/[39m timer/replay._sample_frac [1m1.89[22m [34m/
timer/replay._sample_avg [1m0.05[22m [34m/[39m timer/replay._sample_min [1m0.03[22m [34m/[39m timer/replay._sample_max [1m0.12[22m [34m/[39m timer/agent.save_count [1m0[22m [34m/[39m timer/agent.save_total [1m0[22m [34m/[39m timer/agent.save_frac [1m0[22m [34m/
timer/agent.policy_count [1m1294[22m [34m/[39m timer/agent.policy_total [1m12.9[22m [34m/[39m timer/agent.policy_frac [1m0.04[22m [34m/[39m timer/agent.policy_avg [1m1e-2[22m [34m/[39m timer/agent.policy_min [1m8.4e-3[22m [34m/
timer/agent.policy_max [1m0.02[22m [34m/[39m timer/dataset_train_count [1m647[22m [34m/[39m timer/dataset_train_total [1m0.09[22m [34m/[39m timer/dataset_train_frac [1m3e-4[22m [34m/[39m timer/dataset_train_avg [1m1.4e-4[22m [34m/
timer/dataset_train_min [1m1.2e-4[22m [34m/[39m timer/dataset_train_max [1m5.3e-4[22m [34m/[39m timer/agent.train_count [1m647[22m [34m/[39m timer/agent.train_total [1m254.83[22m [34m/[39m timer/agent.train_frac [1m0.85[22m [34m/
timer/agent.train_avg [1m0.39[22m [34m/[39m timer/agent.train_min [1m0.39[22m [34m/[39m timer/agent.train_max [1m0.41[22m [34m/[39m timer/agent.report_count [1m2[22m [34m/[39m timer/agent.report_total [1m0.45[22m [34m/[39m timer/agent.report_frac [1m1.5e-3
[34m/[39m timer/agent.report_avg [1m0.23[22m [34m/[39m timer/agent.report_min [1m0.22[22m [34m/[39m timer/agent.report_max [1m0.23[22m [34m/[39m timer/dataset_eval_count [1m1[22m [34m/[39m timer/dataset_eval_total [1m6.9e-5[22m [34m/[39m timer/dataset_eval_frac
[1m2.3e-7[22m [34m/[39m timer/dataset_eval_avg [1m6.9e-5[22m [34m/[39m timer/dataset_eval_min [1m6.9e-5[22m [34m/[39m timer/dataset_eval_max [1m6.9e-5[22m [34m/[39m fps [1m4.31
Episode has 209 steps and return 3.1.
Episode has 162 steps and return 4.1.
Episode has 112 steps and return 2.1.
Episode has 237 steps and return 4.1.
Episode has 41 steps and return 1.1.
Saved chunk: 20240102T020310F218912-0nHtZd7nwlZHm0X7ZLgSSC-1Aiq3v8lzhszsLpIs1eIOw-1024.npz
Episode has 359 steps and return 0.1.
Episode has 181 steps and return 2.1.
[92mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [39m[1mStep 7461[92m[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
episode/length [1m181[22m [34m/[39m episode/score [1m2.1[22m [34m/[39m episode/reward_rate [1m0.97[22m [34m/[39m train/action_mag [1m16[22m [34m/[39m train/action_max [1m16[22m [34m/[39m train/action_mean [1m5.77[22m [34m/[39m train/action_min [1m0[22m [34m/[39m train/action_std [1m3.7
[34m/[39m train/actor_opt_actor_opt_grad_overflow [1m0[22m [34m/[39m train/actor_opt_actor_opt_grad_scale [1m1e4[22m [34m/[39m train/actor_opt_grad_norm [1m0.04[22m [34m/[39m train/actor_opt_grad_steps [1m2860[22m [34m/[39m train/actor_opt_loss
[1m69.35[22m [34m/[39m train/adv_mag [1m1.48[22m [34m/[39m train/adv_max [1m1.47[22m [34m/[39m train/adv_mean [1m0.02[22m [34m/[39m train/adv_min [1m-0.67[22m [34m/[39m train/adv_std [1m0.11[22m [34m/[39m train/cont_avg [1m0.99[22m [34m/[39m train/cont_loss_mean [1m8.2e-4[22m [34m/
train/cont_loss_std [1m0.02[22m [34m/[39m train/cont_neg_acc [1m0.97[22m [34m/[39m train/cont_neg_loss [1m0.08[22m [34m/[39m train/cont_pos_acc [1m1[22m [34m/[39m train/cont_pos_loss [1m2.9e-4[22m [34m/[39m train/cont_pred [1m0.99[22m [34m/[39m train/cont_rate [1m0.99[22m [34m/
train/dyn_loss_mean [1m3.73[22m [34m/[39m train/dyn_loss_std [1m5.86[22m [34m/[39m train/extr_critic_critic_opt_critic_opt_grad_overflow [1m0[22m [34m/[39m train/extr_critic_critic_opt_critic_opt_grad_scale [1m1e4[22m [34m/
train/extr_critic_critic_opt_grad_norm [1m1.35[22m [34m/[39m train/extr_critic_critic_opt_grad_steps [1m2860[22m [34m/[39m train/extr_critic_critic_opt_loss [1m1.6e4[22m [34m/[39m train/extr_critic_mag [1m3.25[22m [34m/
train/extr_critic_max [1m3.25[22m [34m/[39m train/extr_critic_mean [1m1.27[22m [34m/[39m train/extr_critic_min [1m-0.39[22m [34m/[39m train/extr_critic_std [1m0.88[22m [34m/[39m train/extr_return_normed_mag [1m2.44[22m [34m/
train/extr_return_normed_max [1m2.44[22m [34m/[39m train/extr_return_normed_mean [1m0.53[22m [34m/[39m train/extr_return_normed_min [1m-0.26[22m [34m/[39m train/extr_return_normed_std [1m0.35[22m [34m/[39m train/extr_return_rate [1m0.77[22m [34m/
train/extr_return_raw_mag [1m6.69[22m [34m/[39m train/extr_return_raw_max [1m6.69[22m [34m/[39m train/extr_return_raw_mean [1m1.34[22m [34m/[39m train/extr_return_raw_min [1m-0.88[22m [34m/[39m train/extr_return_raw_std [1m0.99[22m [34m/
train/extr_reward_mag [1m1.01[22m [34m/[39m train/extr_reward_max [1m1.01[22m [34m/[39m train/extr_reward_mean [1m0.02[22m [34m/[39m train/extr_reward_min [1m-0.44[22m [34m/[39m train/extr_reward_std [1m0.13[22m [34m/[39m train/image_loss_mean [1m8.48[22m [34m/
train/image_loss_std [1m9.51[22m [34m/[39m train/model_loss_mean [1m10.75[22m [34m/[39m train/model_loss_std [1m11.49[22m [34m/[39m train/model_opt_grad_norm [1m152.59[22m [34m/[39m train/model_opt_grad_steps [1m2850[22m [34m/[39m train/model_opt_loss
[1m529.05[22m [34m/[39m train/model_opt_model_opt_grad_overflow [1m0[22m [34m/[39m train/model_opt_model_opt_grad_scale [1m49.28[22m [34m/[39m train/policy_entropy_mag [1m1.97[22m [34m/[39m train/policy_entropy_max [1m1.97[22m [34m/
train/policy_entropy_mean [1m0.4[22m [34m/[39m train/policy_entropy_min [1m0.08[22m [34m/[39m train/policy_entropy_std [1m0.36[22m [34m/[39m train/policy_logprob_mag [1m7.44[22m [34m/[39m train/policy_logprob_max [1m-9.5e-3[22m [34m/
train/policy_logprob_mean [1m-0.4[22m [34m/[39m train/policy_logprob_min [1m-7.44[22m [34m/[39m train/policy_logprob_std [1m1.01[22m [34m/[39m train/policy_randomness_mag [1m0.7[22m [34m/[39m train/policy_randomness_max [1m0.7[22m [34m/
train/policy_randomness_mean [1m0.14[22m [34m/[39m train/policy_randomness_min [1m0.03[22m [34m/[39m train/policy_randomness_std [1m0.13[22m [34m/[39m train/post_ent_mag [1m37.49[22m [34m/[39m train/post_ent_max [1m37.49[22m [34m/
train/post_ent_mean [1m23.93[22m [34m/[39m train/post_ent_min [1m10.45[22m [34m/[39m train/post_ent_std [1m4.37[22m [34m/[39m train/prior_ent_mag [1m58.24[22m [34m/[39m train/prior_ent_max [1m58.24[22m [34m/[39m train/prior_ent_mean [1m28.01[22m [34m/
train/prior_ent_min [1m12.21[22m [34m/[39m train/prior_ent_std [1m6.9[22m [34m/[39m train/rep_loss_mean [1m3.73[22m [34m/[39m train/rep_loss_std [1m5.86[22m [34m/[39m train/reward_avg [1m5.8e-3[22m [34m/[39m train/reward_loss_mean [1m0.04[22m [34m/
train/reward_loss_std [1m0.22[22m [34m/[39m train/reward_max_data [1m1[22m [34m/[39m train/reward_max_pred [1m1[22m [34m/[39m train/reward_neg_acc [1m1[22m [34m/[39m train/reward_neg_loss [1m0.03[22m [34m/[39m train/reward_pos_acc [1m0.96[22m [34m/
train/reward_pos_loss [1m0.87[22m [34m/[39m train/reward_pred [1m5.7e-3[22m [34m/[39m train/reward_rate [1m0.01[22m [34m/[39m train/transition_tokens_loss_mean [1m2.1e-3[22m [34m/[39m train/transition_tokens_loss_std [1m7.9e-4[22m [34m/
train_stats/sum_log_reward [1m2.39[22m [34m/[39m train_stats/max_log_achievement_collect_drink [1m9.86[22m [34m/[39m train_stats/max_log_achievement_collect_sapling [1m1.29[22m [34m/
train_stats/max_log_achievement_collect_wood [1m0.43[22m [34m/[39m train_stats/max_log_achievement_defeat_zombie [1m0[22m [34m/[39m train_stats/max_log_achievement_eat_cow [1m0.14[22m [34m/
train_stats/max_log_achievement_place_plant [1m1.14[22m [34m/[39m train_stats/max_log_achievement_wake_up [1m1.71[22m [34m/[39m train_stats/mean_log_entropy [1m0.47[22m [34m/[39m report/cont_avg [1m1[22m [34m/[39m report/cont_loss_mean
[1m1.7e-5[22m [34m/[39m report/cont_loss_std [1m3.3e-4[22m [34m/[39m report/cont_neg_acc [1m1[22m [34m/[39m report/cont_neg_loss [1m8e-4[22m [34m/[39m report/cont_pos_acc [1m1[22m [34m/[39m report/cont_pos_loss [1m1.4e-5[22m [34m/[39m report/cont_pred [1m1[22m [34m/
report/cont_rate [1m1[22m [34m/[39m report/dyn_loss_mean [1m3.58[22m [34m/[39m report/dyn_loss_std [1m5.61[22m [34m/[39m report/image_loss_mean [1m6.21[22m [34m/[39m report/image_loss_std [1m6.93[22m [34m/[39m report/model_loss_mean [1m8.39[22m [34m/
report/model_loss_std [1m9.4[22m [34m/[39m report/post_ent_mag [1m36.34[22m [34m/[39m report/post_ent_max [1m36.34[22m [34m/[39m report/post_ent_mean [1m23.12[22m [34m/[39m report/post_ent_min [1m8.53[22m [34m/[39m report/post_ent_std [1m4.85[22m [34m/
report/prior_ent_mag [1m58.22[22m [34m/[39m report/prior_ent_max [1m58.22[22m [34m/[39m report/prior_ent_mean [1m26.8[22m [34m/[39m report/prior_ent_min [1m10.99[22m [34m/[39m report/prior_ent_std [1m7.42[22m [34m/[39m report/rep_loss_mean [1m3.58[22m [34m/
report/rep_loss_std [1m5.61[22m [34m/[39m report/reward_avg [1m6.3e-3[22m [34m/[39m report/reward_loss_mean [1m0.03[22m [34m/[39m report/reward_loss_std [1m0.22[22m [34m/[39m report/reward_max_data [1m1[22m [34m/[39m report/reward_max_pred [1m1[22m [34m/
report/reward_neg_acc [1m1[22m [34m/[39m report/reward_neg_loss [1m0.02[22m [34m/[39m report/reward_pos_acc [1m1[22m [34m/[39m report/reward_pos_loss [1m0.72[22m [34m/[39m report/reward_pred [1m7.4e-3[22m [34m/[39m report/reward_rate [1m9.8e-3[22m [34m/
report/transition_tokens_loss_mean [1m1.6e-3[22m [34m/[39m report/transition_tokens_loss_std [1m3.7e-4[22m [34m/[39m eval/cont_avg [1m0.99[22m [34m/[39m eval/cont_loss_mean [1m0.04[22m [34m/[39m eval/cont_loss_std [1m0.64[22m [34m/[39m eval/cont_neg_acc
[1m0.43[22m [34m/[39m eval/cont_neg_loss [1m5.88[22m [34m/[39m eval/cont_pos_acc [1m1[22m [34m/[39m eval/cont_pos_loss [1m8.4e-6[22m [34m/[39m eval/cont_pred [1m1[22m [34m/[39m eval/cont_rate [1m0.99[22m [34m/[39m eval/dyn_loss_mean [1m19.26[22m [34m/[39m eval/dyn_loss_std [1m11.25[22m [34m/
eval/image_loss_mean [1m64.85[22m [34m/[39m eval/image_loss_std [1m77.36[22m [34m/[39m eval/model_loss_mean [1m76.63[22m [34m/[39m eval/model_loss_std [1m80.32[22m [34m/[39m eval/post_ent_mag [1m42.98[22m [34m/[39m eval/post_ent_max [1m42.98[22m [34m/
eval/post_ent_mean [1m26.09[22m [34m/[39m eval/post_ent_min [1m9.06[22m [34m/[39m eval/post_ent_std [1m6.04[22m [34m/[39m eval/prior_ent_mag [1m58.22[22m [34m/[39m eval/prior_ent_max [1m58.22[22m [34m/[39m eval/prior_ent_mean [1m32.21[22m [34m/[39m eval/prior_ent_min
[1m12.01[22m [34m/[39m eval/prior_ent_std [1m8.31[22m [34m/[39m eval/rep_loss_mean [1m19.26[22m [34m/[39m eval/rep_loss_std [1m11.25[22m [34m/[39m eval/reward_avg [1m8.5e-3[22m [34m/[39m eval/reward_loss_mean [1m0.18[22m [34m/[39m eval/reward_loss_std [1m1.18[22m [34m/
eval/reward_max_data [1m1[22m [34m/[39m eval/reward_max_pred [1m0.99[22m [34m/[39m eval/reward_neg_acc [1m1[22m [34m/[39m eval/reward_neg_loss [1m0.07[22m [34m/[39m eval/reward_pos_acc [1m0.13[22m [34m/[39m eval/reward_pos_loss [1m7.36[22m [34m/[39m eval/reward_pred
[1m-1.8e-3[22m [34m/[39m eval/reward_rate [1m0.01[22m [34m/[39m eval/transition_tokens_loss_mean [1m2e-3[22m [34m/[39m eval/transition_tokens_loss_std [1m3.9e-4[22m [34m/[39m replay/size [1m7398[22m [34m/[39m replay/inserts [1m1294[22m [34m/[39m replay/samples [1m1e4[22m [34m/
replay/insert_wait_avg [1m3.7e-6[22m [34m/[39m replay/insert_wait_frac [1m1[22m [34m/[39m replay/sample_wait_avg [1m1.4e-6[22m [34m/[39m replay/sample_wait_frac [1m1[22m [34m/[39m eval_replay/size [1m1227[22m [34m/[39m eval_replay/inserts [1m0[22m [34m/
eval_replay/samples [1m16[22m [34m/[39m eval_replay/insert_wait_avg nan [34m/[39m eval_replay/insert_wait_frac nan [34m/[39m eval_replay/sample_wait_avg [1m1.8e-6[22m [34m/[39m eval_replay/sample_wait_frac [1m1[22m [34m/[39m timer/duration
[1m300.18[22m [34m/[39m timer/env.step_count [1m1294[22m [34m/[39m timer/env.step_total [1m13.79[22m [34m/[39m timer/env.step_frac [1m0.05[22m [34m/[39m timer/env.step_avg [1m0.01[22m [34m/[39m timer/env.step_min [1m2.6e-3[22m [34m/[39m timer/env.step_max [1m1.36[22m [34m/
timer/replay._sample_count [1m1e4[22m [34m/[39m timer/replay._sample_total [1m568.12[22m [34m/[39m timer/replay._sample_frac [1m1.89[22m [34m/[39m timer/replay._sample_avg [1m0.05[22m [34m/[39m timer/replay._sample_min [1m1.6e-3[22m [34m/
timer/replay._sample_max [1m0.12[22m [34m/[39m timer/agent.save_count [1m0[22m [34m/[39m timer/agent.save_total [1m0[22m [34m/[39m timer/agent.save_frac [1m0[22m [34m/[39m timer/agent.policy_count [1m1294[22m [34m/[39m timer/agent.policy_total [1m12.83[22m [34m/
timer/agent.policy_frac [1m0.04[22m [34m/[39m timer/agent.policy_avg [1m9.9e-3[22m [34m/[39m timer/agent.policy_min [1m8.4e-3[22m [34m/[39m timer/agent.policy_max [1m0.02[22m [34m/[39m timer/dataset_train_count [1m647[22m [34m/
timer/dataset_train_total [1m0.09[22m [34m/[39m timer/dataset_train_frac [1m3.1e-4[22m [34m/[39m timer/dataset_train_avg [1m1.4e-4[22m [34m/[39m timer/dataset_train_min [1m1.2e-4[22m [34m/[39m timer/dataset_train_max [1m8.6e-4[22m [34m/
timer/agent.train_count [1m647[22m [34m/[39m timer/agent.train_total [1m254.97[22m [34m/[39m timer/agent.train_frac [1m0.85[22m [34m/[39m timer/agent.train_avg [1m0.39[22m [34m/[39m timer/agent.train_min [1m0.39[22m [34m/[39m timer/agent.train_max [1m0.42
[34m/[39m timer/agent.report_count [1m2[22m [34m/[39m timer/agent.report_total [1m0.45[22m [34m/[39m timer/agent.report_frac [1m1.5e-3[22m [34m/[39m timer/agent.report_avg [1m0.23[22m [34m/[39m timer/agent.report_min [1m0.22[22m [34m/[39m timer/agent.report_max
[1m0.23[22m [34m/[39m timer/dataset_eval_count [1m1[22m [34m/[39m timer/dataset_eval_total [1m5.1e-5[22m [34m/[39m timer/dataset_eval_frac [1m1.7e-7[22m [34m/[39m timer/dataset_eval_avg [1m5.1e-5[22m [34m/[39m timer/dataset_eval_min [1m5.1e-5[22m [34m/
timer/dataset_eval_max [1m5.1e-5[22m [34m/[39m fps [1m4.31
Episode has 160 steps and return 4.1.
Episode has 87 steps and return 3.1.
Traceback (most recent call last):
  File "/home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/train.py", line 229, in <module>
    main()
  File "/home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/train.py", line 69, in main
    embodied.run.train_eval(
  File "/home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/embodied/run/train_eval.py", line 146, in train_eval
    driver_train(policy_train, steps=100)
  File "/home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/embodied/core/driver.py", line 42, in __call__
    step, episode = self._step(policy, step, episode)
  File "/home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/embodied/core/driver.py", line 65, in _step
    [fn(trn, i, **self._kwargs) for fn in self._on_steps]
  File "/home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/embodied/core/driver.py", line 65, in <listcomp>
    [fn(trn, i, **self._kwargs) for fn in self._on_steps]
  File "/home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/embodied/run/train_eval.py", line 108, in train_step
    outs, state[0], mets = agent.train(batch[0], state[0])
  File "/home/ziyu/anaconda3/envs/jaxpy39/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/jaxagent.py", line 75, in train
    (outs, state, mets), self.varibs = self._train(
  File "/home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/ninjax.py", line 208, in wrapper
    out, updated = apply(statics, selected, rng, *args, **kw)
  File "<string>", line 1, in <lambda>
KeyboardInterrupt
[31mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [39m[1mTraceback (most recent call last)[31m[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
[31mâ”‚[39m /home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/[1mtrain.py[22m:[94m229[39m in [92m<module>[39m              [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   226                                                                                            [31mâ”‚
[31mâ”‚[39m   227                                                                                            [31mâ”‚
[31mâ”‚[39m   228 [94mif[39m [91m__name__[39m == [33m'__main__'[39m:                                                                 [31mâ”‚
[31mâ”‚[39m [31mâ± [39m229   main()                                                                                   [31mâ”‚
[31mâ”‚[39m   230                                                                                            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/[1mtrain.py[22m:[94m69[39m in [92mmain[39m                   [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m    66 â”‚     eval_env = make_envs(config)  # mode='eval'                                          [31mâ”‚
[31mâ”‚[39m    67 â”‚     cleanup += [env, eval_env]                                                           [31mâ”‚
[31mâ”‚[39m    68 â”‚     agent = agt.Agent(env.obs_space, env.act_space, step, config)                        [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 69 â”‚     embodied.run.train_eval(                                                             [31mâ”‚
[31mâ”‚[39m    70 â”‚   â”‚     agent, env, eval_env, replay, eval_replay, logger, args)                         [31mâ”‚
[31mâ”‚[39m    71 â”‚                                                                                          [31mâ”‚
[31mâ”‚[39m    72 â”‚   [94melif[39m args.script == [33m'train_holdout'[39m:                                                   [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/embodied/run/[1mtrain_eval.py[22m:[94m146[39m in     [31mâ”‚
[31mâ”‚[39m [92mtrain_eval[39m                                                                                       [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   143 â”‚     [96mprint[39m([33m'Starting evaluation at step'[39m, [96mint[39m(step))                                      [31mâ”‚
[31mâ”‚[39m   144 â”‚     driver_eval.reset()                                                                  [31mâ”‚
[31mâ”‚[39m   145 â”‚     driver_eval(policy_eval, episodes=[96mmax[39m([96mlen[39m(eval_env), args.eval_eps))                 [31mâ”‚
[31mâ”‚[39m [31mâ± [39m146 â”‚   driver_train(policy_train, steps=[94m100[39m)                                                  [31mâ”‚
[31mâ”‚[39m   147 â”‚   [94mif[39m should_save(step):                                                                  [31mâ”‚
[31mâ”‚[39m   148 â”‚     checkpoint.save()                                                                    [31mâ”‚
[31mâ”‚[39m   149   logger.write()                                                                           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/embodied/core/[1mdriver.py[22m:[94m42[39m in         [31mâ”‚
[31mâ”‚[39m [92m__call__[39m                                                                                         [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   39   [94mdef[39m [92m__call__[39m([96mself[39m, policy, steps=[94m0[39m, episodes=[94m0[39m):                                          [31mâ”‚
[31mâ”‚[39m   40 â”‚   step, episode = [94m0[39m, [94m0[39m                                                                    [31mâ”‚
[31mâ”‚[39m   41 â”‚   [94mwhile[39m step < steps [95mor[39m episode < episodes:                                               [31mâ”‚
[31mâ”‚[39m [31mâ± [39m42 â”‚     step, episode = [96mself[39m._step(policy, step, episode)                                     [31mâ”‚
[31mâ”‚[39m   43                                                                                             [31mâ”‚
[31mâ”‚[39m   44   [94mdef[39m [92m_step[39m([96mself[39m, policy, step, episode):                                                   [31mâ”‚
[31mâ”‚[39m   45 â”‚   [94massert[39m [96mall[39m([96mlen[39m(x) == [96mlen[39m([96mself[39m._env) [94mfor[39m x [95min[39m [96mself[39m._acts.values())                       [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/embodied/core/[1mdriver.py[22m:[94m65[39m in [92m_step[39m   [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   62 â”‚   [94mfor[39m i [95min[39m [96mrange[39m([96mlen[39m([96mself[39m._env)):                                                         [31mâ”‚
[31mâ”‚[39m   63 â”‚     trn = {k: v[i] [94mfor[39m k, v [95min[39m trns.items()}                                              [31mâ”‚
[31mâ”‚[39m   64 â”‚     [[96mself[39m._eps[i][k].append(v) [94mfor[39m k, v [95min[39m trn.items()]                                   [31mâ”‚
[31mâ”‚[39m [31mâ± [39m65 â”‚     [fn(trn, i, **[96mself[39m._kwargs) [94mfor[39m fn [95min[39m [96mself[39m._on_steps]                                 [31mâ”‚
[31mâ”‚[39m   66 â”‚     step += [94m1[39m                                                                             [31mâ”‚
[31mâ”‚[39m   67 â”‚   [94mif[39m obs[[33m'is_last'[39m].any():                                                                [31mâ”‚
[31mâ”‚[39m   68 â”‚     [94mfor[39m i, done [95min[39m [96menumerate[39m(obs[[33m'is_last'[39m]):                                             [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/embodied/core/[1mdriver.py[22m:[94m65[39m in         [31mâ”‚
[31mâ”‚[39m [92m<listcomp>[39m                                                                                       [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   62 â”‚   [94mfor[39m i [95min[39m [96mrange[39m([96mlen[39m([96mself[39m._env)):                                                         [31mâ”‚
[31mâ”‚[39m   63 â”‚     trn = {k: v[i] [94mfor[39m k, v [95min[39m trns.items()}                                              [31mâ”‚
[31mâ”‚[39m   64 â”‚     [[96mself[39m._eps[i][k].append(v) [94mfor[39m k, v [95min[39m trn.items()]                                   [31mâ”‚
[31mâ”‚[39m [31mâ± [39m65 â”‚     [fn(trn, i, **[96mself[39m._kwargs) [94mfor[39m fn [95min[39m [96mself[39m._on_steps]                                 [31mâ”‚
[31mâ”‚[39m   66 â”‚     step += [94m1[39m                                                                             [31mâ”‚
[31mâ”‚[39m   67 â”‚   [94mif[39m obs[[33m'is_last'[39m].any():                                                                [31mâ”‚
[31mâ”‚[39m   68 â”‚     [94mfor[39m i, done [95min[39m [96menumerate[39m(obs[[33m'is_last'[39m]):                                             [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/embodied/run/[1mtrain_eval.py[22m:[94m108[39m in     [31mâ”‚
[31mâ”‚[39m [92mtrain_step[39m                                                                                       [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   105 â”‚     #----give intrinsic rewards to batch sampled>>>>                                     [31mâ”‚
[31mâ”‚[39m   106 â”‚     batch[[94m0[39m][[33m'rnd'[39m] = get_intrinsic_and_update_rnd(batch)                                [31mâ”‚
[31mâ”‚[39m   107 â”‚     #-------------------------------------------<<<<                                     [31mâ”‚
[31mâ”‚[39m [31mâ± [39m108 â”‚     outs, state[[94m0[39m], mets = agent.train(batch[[94m0[39m], state[[94m0[39m])                               [31mâ”‚
[31mâ”‚[39m   109 â”‚     metrics.add(mets, prefix=[33m'train'[39m)                                                    [31mâ”‚
[31mâ”‚[39m   110 â”‚     [94mif[39m [33m'priority'[39m [95min[39m outs:                                                               [31mâ”‚
[31mâ”‚[39m   111 â”‚   â”‚   train_replay.prioritize(outs[[33m'key'[39m], outs[[33m'priority'[39m])                             [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ziyu/anaconda3/envs/jaxpy39/lib/python3.10/[1mcontextlib.py[22m:[94m79[39m in [92minner[39m                       [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m    76 â”‚   â”‚   [1m@wraps[22m(func)                                                                       [31mâ”‚
[31mâ”‚[39m    77 â”‚   â”‚   [94mdef[39m [92minner[39m(*args, **kwds):                                                          [31mâ”‚
[31mâ”‚[39m    78 â”‚   â”‚   â”‚   [94mwith[39m [96mself[39m._recreate_cm():                                                      [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 79 â”‚   â”‚   â”‚   â”‚   [94mreturn[39m func(*args, **kwds)                                                 [31mâ”‚
[31mâ”‚[39m    80 â”‚   â”‚   [94mreturn[39m inner                                                                       [31mâ”‚
[31mâ”‚[39m    81                                                                                            [31mâ”‚
[31mâ”‚[39m    82                                                                                            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/[1mjaxagent.py[22m:[94m75[39m in [92mtrain[39m               [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m    72 â”‚   #----                                                                                  [31mâ”‚
[31mâ”‚[39m    73 â”‚   data = [96mself[39m._convert_inps(data, [96mself[39m.policy_devices)                                   [31mâ”‚
[31mâ”‚[39m    74 â”‚   #----                                                                                  [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 75 â”‚   (outs, state, mets), [96mself[39m.varibs = [96mself[39m._train(                                        [31mâ”‚
[31mâ”‚[39m    76 â”‚   â”‚   [96mself[39m.varibs, rng, data, state)                                                     [31mâ”‚
[31mâ”‚[39m    77 â”‚   outs = [96mself[39m._convert_outs(outs, [96mself[39m.train_devices)                                    [31mâ”‚
[31mâ”‚[39m    78 â”‚   [96mself[39m._updates.increment()                                                              [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ziyu/code/side_codes/Dynamic_model/DLLM-ziyu/LID-rnd/[1mninjax.py[22m:[94m208[39m in [92mwrapper[39m              [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   205 â”‚     [94mreturn[39m state                                                                         [31mâ”‚
[31mâ”‚[39m   206 â”‚   [94melse[39m:                                                                                  [31mâ”‚
[31mâ”‚[39m   207 â”‚     selected = {k: v [94mfor[39m k, v [95min[39m state.items() [94mif[39m k [95min[39m wrapper.keys}                     [31mâ”‚
[31mâ”‚[39m [31mâ± [39m208 â”‚     out, updated = apply(statics, selected, rng, *args, **kw)                            [31mâ”‚
[31mâ”‚[39m   209 â”‚     [94mreturn[39m out, {**state, **updated}                                                     [31mâ”‚
[31mâ”‚[39m   210   [94mreturn[39m wrapper                                                                           [31mâ”‚
[31mâ”‚[39m   211                                                                                            [31mâ”‚
[31mâ”‚[39m in [92m<lambda>[39m:[94m1[39m                                                                                    [31mâ”‚
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[1mKeyboardInterrupt